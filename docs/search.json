[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mihnea POPA",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file.Download CV\nDownload PDF file.\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nOn r√©sout l‚Äô√©quation :\n\\[\nx^2 - 4 = 0\n\\]\nDonc :\n\\[\nx = \\pm 2\n\\]\n\n\n\n\n\nVoir la solution\n\nOn r√©sout :\n\\[x^2 - 4 = 0\\]\nDonc \\[x = \\pm 2\\]"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Let‚Äôs investigate the relationship between fuel efficiency (mpg) and engine displacement (disp) from the mtcars dataset. Those variables have a correlation of -0.85.\n\n\nHere is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Modelling a linear time series by an ARIMA model and prediction\n\n\n\n\n\n\nMihnea POPA / Paul LEMOINE\n\n\nMay 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nThesis on descriptive statistics on taxation in France\n\n\n\n\n\n\nMihnea POPA / Tristan FABRE\n\n\nDec 1, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project2/index.html",
    "href": "projects/project2/index.html",
    "title": "Modelling a linear time series  by an ARIMA model and prediction",
    "section": "",
    "text": "The selected series corresponds to the industrial production index (base 2021) in the sector of Woodworking and manufacture of wood and cork products, except furniture, manufacture of basketry and wickerwork products. It is characterized by a monthly frequency and covers the period from January 1990 to February 2025. This is a CVS-CJO index, which means that the series is adjusted for seasonal and working day variations, so it is already pre-processed to eliminate regular seasonal effects. INSEE - Monthly Data\nDownload PDF file.Download Report Download PDF file.\n\n# Script avec commentaires pour le projet de s√©ries temporelles Paul / Mihnea\n# Premi√®re version: 01 Mai 2025 \n\n#==============================================================================#\n# Packages ---------------------------------------------------------------------\n#==============================================================================#\n\nlibrary(zoo)\nlibrary(tseries)\nlibrary(fUnitRoots)\nlibrary(purrr)\nlibrary(lmtest)\n\n#==============================================================================#\n# Partie 1 Les donn√©es ---------------------------------------------------------\n#==============================================================================#\n\n  #Importation et nettoyage de la base\ndata &lt;- read.csv(\"valeurs_mensuelles.csv\", sep = \",\")\ndata &lt;- data[-c(1:3), ] #Enlever les premi√®res lignes qui donnent l'ID de la base et la date de mise √† jour\ndata &lt;- data[,-c(3) ] #Enlever la derni√®re colonne avec les codes de chaque observation\ncolnames(data) &lt;- c(\"dates\",\"value\")\ndates_char &lt;- as.character(data$dates)\ndata$value &lt;- as.numeric(data$value)\ndates_char[[1]]; dates_char[length(dates_char)]\n\n[1] \"1990-01\"\n\n\n[1] \"2025-12\"\n\ndates &lt;- as.yearmon(seq(from=1990, to=2025+11/12, by=1/12))\nvalue &lt;- zoo(data$value, order.by=dates)\n\n  #Visualisation de la s√©rie temporelle et de son ACF\n\nplot(value)\n\n\n\n\n\n\n\nacf(value)\n\n\n\n\n\n\n\n      #La s√©rie ne pr√©sente pas de saisonnalit√© au vu de son √©volution et de son ACF.\n      #Cependant, graphiquement nous remarquons qu'elle n'est pas stationnaire.\n\n  #Diff√©renciation de la s√©rie et visualisation de dvalue\ndvalue &lt;- diff(value,1)\nplot(dvalue)\n\n\n\n\n\n\n\nacf(dvalue)\n\n\n\n\n\n\n\n      # La s√©rie diff√©renci√©e semble stationnaire et ne pr√©sente pas de saisonnalit√©\n      # Pas de signe visible √† l'oeil de tendance, donc a priori, la s√©rie n'est pas\n      # int√©gr√©e, i.e. n'a pas une racine unitaire.\n      # On va toutefois tester √ßa plus pr√©cis√©ment avec un test de racine unitaire \n\n  #Mod√®le de regression lin√©aire pour savoir quel test de racine unitaire faire\ndvalue &lt;- zoo(dvalue, order.by=dates)\nsummary(lm(dvalue ~ dates))\n\n\nCall:\nlm(formula = dvalue ~ dates)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-34.063  -2.131  -0.124   2.090  31.798 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) 17.592350  46.996939   0.374    0.708\ndates       -0.008821   0.023405  -0.377    0.706\n\nResidual standard error: 5.055 on 430 degrees of freedom\nMultiple R-squared:  0.0003302, Adjusted R-squared:  -0.001995 \nF-statistic: 0.142 on 1 and 430 DF,  p-value: 0.7064\n\n      #Au vu de la r√©gression lin√©aire, nous sommes dans le cas pas centr√© et pas de tendance visible\n      #On va alors effectuer un test de Perron-Phillips pour v√©rifier la pr√©sence ou non de racine unitaire\npptest_case_stationary &lt;- pp.test(dvalue, alternative = \"stationary\")\npptest_case_stationary$p.value\n\n[1] 0.01\n\n      #On obtient une p-value de 0.01 donc au seuil 98.9% on rejette H0 donc on accepte H1\n      #Dans le test de PP l'hypoth√®se H1 est \"il n'y a pas de racine unitaire\".\n      #On en conclu que la s√©rie diff√©renci√©e dvalue est stationnaire. Pour en √™tre s√ªr on peut faire un test de kpss\nkpss.test(dvalue, null = \"Level\")$p.value\n\n[1] 0.1\n\n      #La p-value obtenue est 0.1 donc au seuil 99% (m√™me 95%) on ne rejette pas H0 donc dvalue est bien stationnaire\n\n  #Repr√©sentation graphique de la s√©rie avant et apr√®s transformation\n#windows()\n#par(mfrow = c(2, 1))\nplot(value)\n\n\n\n\n\n\n\nplot(dvalue)\n\n\n\n\n\n\n\n#==============================================================================#\n# Partie 2 Mod√®les ARMA --------------------------------------------------------\n#==============================================================================#\n\n  #On commence par centrer la variable dvalue\ndvalue_centree &lt;- dvalue - mean(dvalue)\n\n  #On regarde l'ACF de cette nouvelle variable pour d√©terminer l'ordre maximal du c√¥t√© MA\nacf(dvalue_centree)\n\n\n\n\n\n\n\nq_test=2\n      #L'odre maximal du c√¥t√© MA est alors q_test = 2\n\n  #On regarde le PACF de cette nouvelle variable pour d√©terminer l'ordre maximal du c√¥t√© AR\npacf(dvalue_centree)\n\n\n\n\n\n\n\np_test=3\n      #L'odre maximal du c√¥t√© AR est alors p_test = 3\n\n  #Cr√©ation de la fonction de test Box-Ljung pour v√©rifier que les r√©sidus ne sont pas corr√©l√©s\nQtests &lt;- function(series, nb_lags_max_Portmanteau_test = 24, fitdf = 0) {\n  pvals &lt;- apply(X = matrix(1:nb_lags_max_Portmanteau_test), MARGIN = 1, \n                 FUN = function(l) {\n                   if (l &lt;= fitdf) {\n                     pval &lt;- NA\n                   } else {\n                     pval &lt;- Box.test(series, lag = l, type = \"Ljung-Box\", fitdf = fitdf)$p.value\n                   }\n                   return(c(\"lag\" = l, \"pval\" = pval))\n                 })\n  return(t(pvals))\n}\n\n  #On cr√©e tous les mod√®les possibles pour p&lt;=p_test et q&lt;=q_test\npqs &lt;- expand.grid(0:p_test,0:q_test)\nmat &lt;- matrix(NA, nrow=p_test +1, ncol=q_test +1)\nrownames(mat) &lt;- paste0(\"p=\",0:p_test) #renomme les lignes\ncolnames(mat) &lt;- paste0(\"q=\",0:q_test) #renomme les colonnes\nAICs &lt;- mat #matrice ou assigner les AIC\nBICs &lt;- mat #matrice ou assigner les BIC\nfor (row in 1:dim(pqs)[1]){\n  p &lt;- pqs[row,1]\n  q &lt;- pqs[row,2]\n  if ((p==0)&&(q==2)) {print(c(p,q))}\n  estim &lt;- arima(dvalue_centree,c(p,0,q), include.mean=F) #tente d'estimer l'ARIMA\n \n  q_tests = Qtests(estim$residuals, nb_lags_max_Portmanteau_test = 30, \n         fitdf = length(estim$coef))\n  if ((p==0)&&(q==2)) {print(q_tests)}\n  if ((p==0)&&(q==2)) {print(coeftest(estim))}\n  AICs[p+1,q+1] &lt;- if (class(estim)==\"try-error\") NA else estim$aic\n  BICs[p+1,q+1] &lt;- if (class(estim)==\"try-error\") NA else BIC(estim)\n}\n\n[1] 0 2\n      lag      pval\n [1,]   1        NA\n [2,]   2        NA\n [3,]   3 0.5524487\n [4,]   4 0.8336335\n [5,]   5 0.7997667\n [6,]   6 0.8927779\n [7,]   7 0.7102150\n [8,]   8 0.8155912\n [9,]   9 0.8853309\n[10,]  10 0.9255650\n[11,]  11 0.9285630\n[12,]  12 0.9342528\n[13,]  13 0.9439155\n[14,]  14 0.9210362\n[15,]  15 0.9066371\n[16,]  16 0.9380520\n[17,]  17 0.9202788\n[18,]  18 0.9461022\n[19,]  19 0.8702773\n[20,]  20 0.9037391\n[21,]  21 0.9272577\n[22,]  22 0.9447795\n[23,]  23 0.9615493\n[24,]  24 0.9036737\n[25,]  25 0.9262018\n[26,]  26 0.9431918\n[27,]  27 0.9473225\n[28,]  28 0.9574999\n[29,]  29 0.9694680\n[30,]  30 0.9739654\n\nz test of coefficients:\n\n     Estimate Std. Error z value  Pr(&gt;|z|)    \nma1 -0.307170   0.046560 -6.5973 4.187e-11 ***\nma2 -0.205355   0.046174 -4.4474 8.692e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n  #On d√©termine la validit√© des mod√®les\n\n      #Avec les tests du porte-manteau, on en d√©duit que les mod√®les o√π les r√©sidus sont bien d√©cor√©ll√©s au seuil 99% sont:\n        # ARMA( 3 , 0 ) ; ARMA( 1 , 1 ) ; ARMA( 2 , 1 ) ; ARMA( 3 , 1 ) ; ARMA( 0 , 2 ) ; ARMA( 1 , 2 ) ; ARMA( 2 , 2 ) ; ARMA( 3 , 2 ) ;\n      #AVec les tests de Student, on en d√©duit que les mod√®les o√π les coefficients de plus grand ordre sont significatifs sont:\n        # ARMA( 1 , 0 ) ; ARMA( 2 , 0 ) ; ARMA( 0 , 1 ) ; ARMA( 1 , 1 ) ; ARMA( 0 , 2 )\n\n      #Ainsi, les mod√®les possibles pour dvalue_centr√©e (ceux qui passent les deux tests de validit√©s) sont:\n        # ARMA( 1 , 1 ) ; ARMA( 0 , 2 )\n  \n  #On d√©termine les meilleurs mod√®les avec AIC , BIC\nAICs\n\n         q=0      q=1      q=2\np=0 2626.188 2594.061 2577.748\np=1 2609.066 2579.489 2579.379\np=2 2589.315 2579.415 2581.357\np=3 2584.691 2581.342 2582.358\n\n        #Au sens de AIC, le meilleur mod√®le est ARMA(0 , 2 )\nBICs\n\n         q=0      q=1      q=2\np=0 2630.256 2602.198 2589.953\np=1 2617.203 2591.694 2595.653\np=2 2601.520 2595.689 2601.699\np=3 2600.965 2601.684 2606.769\n\n        #Au sens de BIC, le meilleur mod√®le est ARMA( 0 , 2) \narima002 &lt;- arima(dvalue_centree, order = c(0, 0, 2), include.mean = FALSE)\narima101 &lt;- arima(dvalue_centree, order = c(1, 0, 1), include.mean = FALSE)\n\n  #On d√©termine le meilleur mod√®le parmi les deux pr√©c√©dants avec le crit√®re du R^2 ajust√©\n\nAdj_R2 &lt;- function(model){\n  p &lt;- model$arma[[1]] # ordre AR\n  q &lt;- model$arma[[2]] # ordre MA\n  ss_res &lt;- sum(model$residuals[-1]^2) # Modele ARMA sur dspread, perd premi√®re date\n  ss_tot &lt;- sum(dvalue_centree^2)\n  n &lt;- length(dvalue_centree)\n  adj_r2 &lt;- 1 - (ss_res / (n - (p + q + 1))) / (ss_tot / (n - 1))\n  return(adj_r2)\n}\nAdj_R2(arima101)\n\n[1] 0.110115\n\nAdj_R2(arima002)\n\n[1] 0.1136935\n\n      #Au sens du crit√®re du R^2, le meilleur mod√®le est ARMA( 0 , 2 )\n\n#### Par cons√©quent, le meilleur mod√®le pour value est ARIMA(0,1,2)\nvalue &lt;- value\nmodel &lt;- arima(value,c(0,1,2), include.mean=F)\n\n#==============================================================================#\n# Partie 3 Pr√©diction ----------------------------------------------------------\n#==============================================================================#\n\n#Avec le mod√®le ARIMA(0,1,2), la pr√©diction devenait constante √† partir de l'horizon 2\n#Ainsi, on a chois de prendre l'autre mod√®le valide √† savoir le mod√®le ARIMA(1,1,1)\n\n#Avoir le theta, le phi et le sigma avec le mod√®le ARIMA(1,1,1)\nsigma2 &lt;- arima101$sigma2\nphi &lt;- coef(arima101)[\"ar1\"]  \ntheta &lt;- coef(arima101)[\"ma1\"]  \n\n#Fixer les param√®tres de la pr√©diction\nn_value &lt;- length(value)\nhorizon &lt;- 5\nstart_pred &lt;- n_value - horizon\nvalue_vraie &lt;- as.numeric(value)\n\n#Effectuer la pr√©diction\nfit &lt;- arima(value_vraie[1:(n_value - horizon)], order = c(1, 1, 1))\n \nprediction &lt;- function(phi, theta, value_vraie, start_pred, horizon) {\n  val1 &lt;- value_vraie[start_pred]   #t_X_t                          \n  val2 &lt;- val1 + phi * (val1 - value_vraie[start_pred - 1]) \n  var_vec &lt;- numeric(horizon + 1)\n  #t_X_t+1\n  var_vec[1]  &lt;- val1 \n  var_vec[2]  &lt;- val2 \n  # Calculer les valeurs pour h = 2 √† horizon\n  for (h in 2:horizon) {\n    var_vec[h+1] &lt;- (1 / (1 - phi)) * (val2 - phi * val1 + (val1 - val2) * phi^h) #t_X_t+h\n  } \n  # Retourner le vecteur complet\n  return(var_vec)\n}\n#Calculer la variance des √©carts\nvariance &lt;- function(phi, theta, sigma2, horizon) {\n  # Initialise vecteur r√©sultats\n  var_vec &lt;- numeric(horizon + 1)\n  var_vec[1] &lt;- 0  # pour h=0\n  \n  for (h in 1:horizon) {\n    sum_k &lt;- 0\n    for (k in 0:(h-1)) {\n      val_k &lt;- (1 - phi^(k+1) + theta + theta * phi^k) / (1 - phi)\n      sum_k &lt;- sum_k + val_k^2\n    }\n    var_vec[h+1] &lt;- sigma2 * sum_k\n  }\n  \n  return(var_vec)\n}\n\n#Cr√©er la base avec toutes les infos de la pr√©dition\n\npred &lt;- data.frame(\n  pred = prediction(phi, theta, value_vraie, start_pred, horizon),\n  se = variance(phi, theta, sigma2, horizon))\n\n\n# Cr√©er la s√©rie pr√©dite et la s√©rie des bornes de l'intervalle de confiance\npredicted_values &lt;- ts(pred$pred, start = start_pred)\nlower_95 &lt;- ts(pred$pred - 1.96 * pred$se, start = start_pred)\nupper_95 &lt;- ts(pred$pred + 1.96 * pred$se, start = start_pred)\n\n# Tracer la s√©rie originale et les pr√©dictions\nplot(value_vraie, type=\"l\", xlim = c(n_value - 2 * horizon, n_value), ylim = range(c(value_vraie[(n_value - 2*horizon):n_value], lower_95, upper_95)+c(-10,10), na.rm = TRUE), #Enlever le lower_95 et le upper_95 pour une meilleur fen√™tre\n     col = \"black\", lwd = 2, main = \"Pr√©vision ARIMA(1,1,1) pour les derni√®res valeurs\",\n     ylab = \"Valeur\", xlab = \"Temps\")\n\n# Ajouter les pr√©dictions et les intervalles\nlines(predicted_values, col = \"blue\", lwd = 2)\nlines(lower_95, col = \"red\", lty = 2)\nlines(upper_95, col = \"red\", lty = 2)\n\nlegend(\"topleft\", legend = c(\"S√©rie r√©elle\", \"Pr√©diction\", \"Intervalle 95%\"),\n       col = c(\"black\", \"blue\", \"red\"), lty = c(1,1,2), lwd = 2)\n\n\n\n\n\n\n\n# Tracer la s√©rie originale et les pr√©dictions\nplot(value_vraie, type=\"l\", xlim = c(n_value - 2 * horizon, n_value), ylim = range(c(value_vraie[(n_value - 2*horizon):n_value])+c(-10,10), na.rm = TRUE), #Enlever le lower_95 et le upper_95 pour une meilleur fen√™tre\n     col = \"black\", lwd = 2, main = \"Pr√©vision ARIMA(1,1,1) pour les derni√®res valeurs\",\n     ylab = \"Valeur\", xlab = \"Temps\")\n\n# Ajouter les pr√©dictions et les intervalles\nlines(predicted_values, col = \"blue\", lwd = 2)\nlines(lower_95, col = \"red\", lty = 2)\nlines(upper_95, col = \"red\", lty = 2)\n\nlegend(\"topleft\", legend = c(\"S√©rie r√©elle\", \"Pr√©diction\", \"Intervalle 95%\"),\n       col = c(\"black\", \"blue\", \"red\"), lty = c(1,1,2), lwd = 2)"
  },
  {
    "objectID": "projects/project2/index.html#sub-header",
    "href": "projects/project2/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "projects/fiscalite/index.html",
    "href": "projects/fiscalite/index.html",
    "title": "Thesis on descriptive statistics on taxation in France",
    "section": "",
    "text": "Presentation of the project\nThis thesis corresponds to descriptive statistics established using the ESS survey and SAS language in order to examine which taxation system best suits which society. It will first study the relationship between trust in institutions and support for a given tax policy. It will then show that this support also depends on more concrete variables such as age, income, or education level. Finally, we will compare tax preferences to determine, without going as far as ideals, the strong values that govern societies. In other words, tax norms are always based on social values that need to be updated.\nDownload PDF file.Download Report\n\n\nPresentation of the report\nIn this part, you can display the report and read it without downloading it.\n\n\nShow the report\n\nDownload PDF file.\n\n\n\nPresentation of the code\nThis part will allow you to navigate through the SAS code made in order to have the plots in the thesis. The code is separated in three parts (Import the data, Structure the data, Use the data), each one with multiple subparts.\n\nPart 1: Import the ESS data\n\n\nImport the data with the chosen variables\n\nCr√©ation de la libraire o√π se situe la base de donn√©es\nlibname ess \"W:\\Telechargements\";\nImportation de la base de donn√©es avec les variables retenues\ndata ess;\nset ess.ess;\nkeep \ncntry /*Country*/\ngincdif /*Government should reduce differences in income levels (opinion)*/\nagea /*Age of respondent, calculated*/\nhinctnta /*Household's total net income, all sources*/\nsmdfslv /*For fair society, differences in standard of living should be small*/\nsblazy /*Social benefits/services make people lazy*/\nsblwcoa /*Social benefits/services make people less willing care for one another*/\nsblwlka /*Social benefits/services make people less willing look after themselves/family*/\ntxautef /*Tax authorities, how efficient in doing their job*/\nditxssp /*Government decrease/increase taxes and social spending*/\ntxearn /*Taxation for higher versus lower earners*/\nearnpen /*Higher or lower earners should get larger old age pensions*/\nearnueb /*Higher or lower earners should get larger unemployment benefits*/\nlbenent /*Many with very low incomes get less benefit than legally entitled to*/\ninsfben /*Insufficient benefits in country to help people in real need*/\ntrstprl /*Trust in country's parliament*/\nedulvla /*Highest level of education*/\ntrstlgl /*Trust in the legal system*/\ntrstplt /*Trust in politicians*/\ntrstprt /*Trust in political parties*/\nimprich /*Important to be rich, have money and expensive things*/\nipeqopt /*Important that people are treated equally and have equal opportunities*/\nimpfree /*Important to make own decisions and be free*/\niphlppl /*Important to help people and care for others well-being*/\ngvjbevn /*Job for everyone, governments' responsibility*/\ngvhlthc /*Health care for the sick, governments' responsibility*/\ngvslvol /*Standard of living for the old, governments' responsibility*/\ngvslvue /*Standard of living for the unemployed, governments' responsibility*/\ngvcldcr /*Child care services for working parents, governments' responsibility*/\ngvpdlwk /*Paid leave from work to care for sick family, governments' responsibility*/;\nRUN;\n\n\n\nPart 2: Setup of the variables\n\n\nAdd labels to the variables\n\nRenommage des variables avec des labels\ndata ess_label;\nset ess;\nlabel\ncntry = \"Pays de r√©sidence\"\nagea = \"Age\"\ngincdif = \"Le gouvernement doit prendre des mesures pour r√©duire les in√©galit√©s de revenu (1 = D'accord et 5 = Pas d'accord)\"\nhinctnta = \"Revenu\"\nsmdfslv = \"Pour une soci√©t√© juste, les diff√©rences de niveau de vie doivent √™tre faibles (1 = D'accord et 5 = Pas d'accord)\"\nsblazy = \"Les prestations sociales et les services sociaux rendent les personnes paresseuses (1 = Totalement d'accord et 5 = Totalement pas d'accord)\"\nsblwcoa = \"Les prestations sociales et les services sociaux conduisent les personnes √† moins prendre soin des autres (1 = Totalement d'accord et 5 = Totalement pas d'accord)\"\nsblwlka = \"Les prestations sociales et les services sociaux conduisent les personnes √† moins prendre soin de leurs proches (1 = Totalement d'accord et 5 = Totalement pas d'accord)\"\ntxautef = \"Les autorit√©s fiscales sont efficaces (10 = Tr√®s efficaces)\"\nditxssp = \"Il faut augmenter les imp√¥ts et les prestations sociales \"\ntxearn = \"Impots proportionnels (1), progressifs (2) ou √©gal (3) ?\"\nearnpen = \"Retraite en fonction du salaire (1 = Riche retraite plus √©lev√©e, 2 = Retraite √©gale et 3 = Riche retraite moins √©lev√©e\"\nearnueb = \"Les hauts salaires doivent-ils avoir une aide au ch√¥mage plus √©lev√©e (1), √©gale (2) ou moins √©lev√©e (3) ?\"\nlbenent = \"Beaucoup de personnes √† tr√®s faible revenu per√ßoivent moins d'aides que ce dont ils ont acc√®s\"\ntrstprl = \"Avez-vous confiance dans votre parlement ? (0 = Pas confiance et 10 = Confiance)\"\nedulvla = \"Niveau √©ducation maximal\"\ntrstlgl = \"Confiance dans le syst√®me l√©gal\"\ntrstplt = \"Confiance dans les politiciens\"\ntrstprt = \"Confiance dans les partis politiques\"\nimprich = \"Importance d'√™tre riche (1=Oui et 6=Non)\"\nipeqopt = \"Importance d'√™tre √©gaux (1=Oui et 6=Non)\"\nimpfree = \"Importance d'√™tre libre (1=Oui et 6=Non)\"\niphlppl = \"Importance d'aider les autres (1=Oui et 6=Non)\"\ngvjbevn = \"Responsabilit√© du gouvernement pour les emplois pour tous\"\ngvhlthc = \"Resp du gouv pour le syst√®me de sant√©\"\ngvslvol = \"Resp du gouv pour le niveau de vie des personnes √¢g√©es\"\ngvslvue = \"Resp du gouv pour le niveau de vie des ch√¥meurs\"\ngvcldcr = \"Resp du gouv pour le soin aux enfants de travailleurs\"\ngvpdlwk = \"Resp du gouv jour off pay√© afin de prendre soin famille malade\";\nRUN;\n\n\n\nAdd formats to the variables\n\nCr√©ation de formats\n\nPROC FORMAT;\nvalue income\n1-5 = \"Classe populaire et moyenne inf√©rieure\"\n6-8 = \"Classe moyenne\"\n9-10 = \"Classe sup√©rieure\"\n77 = \"A refus√© de r√©pondre\"\n88 = \"Ne sais pas\"\n99 = \"Pas de r√©ponse\";\nrun;\n\nPROC FORMAT;\nvalue age\n0-&lt;15 = \"Enfant ou adolescent\"\n15-&lt;30 = \"Moins de 30 ans\"\n30-65 = \"Entre 30 et 65 ans\"\n65-500 = \"Plus de 65 ans\"\n999 = \"Pas de r√©ponse\";\nRUN;\n\nPROC FORMAT;\nvalue $country\n\"DK\",\"SE\",\"NO\",\"FI\" = \"Mod√®le Social-D√©mocrate\"\n\"FR\",\"BE\",\"LU\",\"DE\",\"AT\" = \"Mod√®le Conservateur/Corporatiste\"\n\"GB\",\"CY\",\"IE\"=\"Mod√®le Lib√©ral\"\n\"AL\",\"HR\",\"ME\",\"MK\",\"SI\",\"XK\",\"SK\",\"CH\",\"NL\",\"GE\",\"IL\",\"TR\",\"EE\",\"IS\",\"RO\",\"RS\",\"BG\",\n\"CZ\",\"HU\",\"PL\",\"RU\",\"UA\",\"LV\",\"LT\",\"ES\",\"IT\",\"GR\",\"PT\" = \"Autre\";\nRUN;\n\nPROC FORMAT;\nvalue presta_sociale\n1 = \" Absolument d'accord\"\n2 = \"Plut√¥t d'accord\"\n3 = \"Indiff√©rent\"\n4 = \"Plut√¥t pas d'accord\"\n5 = \"Absolument pas d'accord\"\n7 = \"A refus√© de r√©pondre\"\n8 = \"Ne sais pas\"\n9 = \"Pas de r√©ponse\";\nrun;\n\nPROC FORMAT;\nvalue resp_gouv\n0-2 = \"Absolument pas d'accord\"\n3-4 = \"Plut√¥t pas d'accord\"\n5 = \"Sans opinion\"\n6-7 = \"Plut√¥t d'accord\"\n8-10 = \"Absolument d'accord\"\n77 = \"A refus√© de r√©pondre\"\n88 = \"Ne sais pas\"\n99 = \"Pas de r√©ponse\";\nRUN;\n\nPROC FORMAT;\nvalue gouv_evolution_impot_ps\n0-2 = \"Absolument pas d'accord\"\n3-4 = \"Plut√¥t pas d'accord\"\n5 = \"Sans opinion\"\n6-7 = \"Plut√¥t d'accord\"\n8-10 = \"Absolument d'accord\"\n77 = \"A refus√© de r√©pondre\"\n88 = \"Ne sais pas\"\n99 = \"Pas de r√©ponse\";\nRUN;\n\nPROC FORMAT;\nvalue aides\n1 = \"Absolument d'accord\"\n2 = \"Plut√¥t d'accord\"\n3 = \"Indiff√©rent\"\n4 = \"Plut√¥t pas d'accord\"\n5 = \"Absolument pas d'accord\"\n7 = \"A refus√© de r√©pondre\"\n8 = \"Ne sais pas\"\n9 = \"Pas de r√©ponse\";\nRUN;\n\nPROC FORMAT;\nvalue comment_taxer\n1 = \"Imp√¥t proportionnel\"\n2 = \"Imp√¥t progressif\"\n3 = \"Imp√¥t √©gal\"\n4 = \"Aucun de ces r√©ponse\"\n7 = \"A refus√© de r√©pondre\"\n8 = \"Ne sais pas\"\n9 = \"Pas de r√©ponse\";\nRUN;\n\nPROC FORMAT;\nvalue education_ISCED\n0 = \"Impossible d'harmoniser\"\n1 = \"Moins que secondaire\"\n2-3 = \"Secondaire\"\n4-5 = \"Sup√©rieur\"\n55 = \"Autre\"\n77 = \"A refus√© de r√©pondre\"\n88 = \"Ne sais pas\"\n99 = \"Pas de r√©ponse\";\nRUN;\n\nPROC FORMAT;\nvalue gouv\n0-3 = \"Pas d'accord\"\n4-6 = \"Sans opinion\"\n7-10 = \"D'accord\"\n77 = \"A refus√© de r√©pondre\"\n88 = \"Ne sais pas\"\n99 = \"Pas de r√©ponse\";\nRUN;\n\nPROC FORMAT;\nvalue imp\n0-2 = \"Important\"\n2-4 = \"Neutre\"\n4-6 = \"Pas important\"\n7 = \"A refus√© de r√©pondre\"\n8 = \"Ne sais pas\"\n9 = \"Pas de r√©ponse\";\nRUN;\n\n\n\nPart 3: Make the plots\n\n\nCreate function for the plots\n\nCr√©ation des macros que l‚Äôon va utiliser\n\n%MACRO panel_var1_var2(variable1,variable2,format1,format2,maxvar1,maxvar2);/*Cette macro cr√©e un panneau suivant les valeurs d'une variable \"variable1\" cod√©e par le format \"format1\" et dans chaque case du panneau repr√©sente les proportions des valeurs de la variable \"variable2\" cod√©e par le format \"format2\"*/\n\n  /*Tri de la table suivant la variable \"variable1\"*/\n  proc sort data=ess_label;\n    by &variable1;\n  run;\n  /*Calcul des pourcentages de chaque valeur de la variable \"variable2\" en groupant selon les valeurs de la variable \"variable1\"*/\n  proc freq data=ess_label\n  (WHERE = (cntry=\"FR\" and &variable1&lt;=&maxvar1 and &variable2&lt;=&maxvar2))\n  noprint;\n    format &variable1 %scan(&format1, 1, %str(%bquote(%')%str(%\"))).;\n    by &variable1;\n    tables &variable2 / out=FreqOut;\n  run;\n  \n  /*Cr√©ation du panneau suivant les valeurs de la variable \"variable1\" en repr√©sentant les proportions des valeurs de la variable \"variable2\" */\n  proc sgpanel data=FreqOut;\n    format &variable1 %scan(&format1, 1, %str(%bquote(%')%str(%\"))).;\n    format &variable2 %scan(&format2, 1, %str(%bquote(%')%str(%\"))).;\n    styleattrs datacontrastcolors=(red green blue) datacolors=(red green blue);\n    panelby &variable1 / columns = 3 novarname noheader;\n    vbar &variable2 /group=&variable1 barwidth=0.5\n  response=percent datalabel ;\n  run;\n  \n%MEND;\n\n\n%MACRO barres_stack(variable);/*Cette macro permet pour une variable \"variable\", qui sera une variable de responsabilit√© du gouvernement, de faire un histogramme horizontal avec barres empil√©es pour repr√©senter cette variable pour les diff√©rentes classes de revenu*/\n\n  /*Tri de la table suivant le revenu avec les observations utiles*/\n  proc sort data=ess_label (WHERE=(cntry= \"FR\" and hinctnta&lt;=10 and &variable&lt;=10 )) out=ess_label_bis ;\n    format hinctnta income.;\n    by hinctnta;\n  run;\n  \n  /*Calcul des pourcentages de chaque valeur de la variable \"variable\" en groupant selon les classes de revenu*/\n\n  proc freq data=ess_label_bis noprint;\n    by hinctnta;\n    tables &variable / out=FreqOut;\n  run;\n  \n  /*Cr√©ation de l'histogramme horizontal avec barres empil√©es*/\n  proc sgplot data=FreqOut NOAUTOLEGEND;\n    styleattrs datacontrastcolors=(red green blue) datacolors=(red green blue);\n    format hinctnta income.;\n    format &variable gouv.;\n    hbar hinctnta / response=Percent group=&variable groupdisplay=stack barwidth=0.5 ;\n    xaxis grid values=(0 to 100 by 10);\n  run;\n  \n%MEND;\n\n\n%MACRO trust(variable1,variable2,maxvar2); /*Cette macro √©tudie le lien entre diff√©rentes variables de confiances \"variable1\" en abscisse et \"variable2\" en ordonn√©es. Elle fait une moyenne sur les pays et repr√©sente une droite de tendance*/\n\n  /*Calcule la moyenne de la variable \"variable1\" pour chaque pays*/\n  proc means data=ess_label (where = (&variable2 &lt;=&maxvar2 and &variable1&lt;50)) noprint;\n    class cntry;\n    var &variable1 &variable2 ;\n    output out=mean_data_2 mean=;\n  run;\n  /*Repr√©sente en abscisses la variable \"variable1\" et en ordonn√©e \"variable2\" avec la droite de tendance*/\n  proc sgplot data=mean_data_2;\n    scatter x=&variable1 y=&variable2 / group=cntry;\n    keylegend / location=outside;\n    reg x=&variable1 y=&variable2 / lineattrs=(color=red) NOMARKERS;\n  run;\n%MEND;\n\n\n%MACRO consensus(variable, format); /*Cette macro √©tudie les fr√©quences de la variable \"variable\" cod√©e par le format \"format\" pour voir s'il existe un consensus aupr√®s des individus*/\n\n  /*Calcul des fr√©quences des valeurs de la variable \"variable\"*/\n  proc freq data=ess_label (WHERE=(cntry=\"FR\" /*and 8&lt;=hinctnta&lt;=10 Pour le dernier consensus */ ));\n    tables %scan(&variable, 1, %str(%bquote(%')%str(%\"))) / out=FreqOut;\n  run;\n  \n/*Cr√©ation del'histogramme pour voir s'il existe un consensus*/\n  proc sgplot data=FreqOut NOAUTOLEGEND;\n    styleattrs datacontrastcolors=(red orange green blue purple red) datacolors=(red orange green blue purple red);\n    VBAR %scan(&variable, 1, %str(%bquote(%')%str(%\"))) /response=percent group=%scan(&variable, 1, %str(%bquote(%')%str(%\")))\n    datalabel; format %scan(&variable, 1, %str(%bquote(%')%str(%\")))\n%scan(&format, 1, %str(%bquote(%')%str(%\"))).;\n  run;\n  \n%MEND;\n\n%MACRO vari_en_fct_pays(variable);/*Cette macro cr√©e un graphique de points avec en abscisse la cat√©gorie de pays (Europe Centrale, Europe du Nord, Lib√©ral, Familialiste) et en ordonn√©e la moyenne de la variable \"variable\" pour chaque pays de chaque cat√©gorie*/\n\n  /*Renvoit la moyenne de la variable \"variable\" pour chaque pays pr√©sent dans la table */\n  proc means data=ess_label (where = (&variable&lt;=4)) noprint;\n    class cntry;\n    var &variable;\n    output out=mean_data mean=;\n  run;\n  /*Selectionne les moyennes qui correspondent aux pays des diff√©rentes cat√©gories √©tudi√©es*/\n  data mean_data;\n    set mean_data;\n    if cntry in (\"DK\",\"SE\",\"NO\",\"FI\",\"FR\",\"BE\",\"LU\", \"DE\",\"AT\",\"GB\",\"CY\",\"IE\");\n  run;\n/*Cr√©ation du graphique de points en regroupant par la cat√©gorie de pays afin d'obtenir des couleurs diff√©rentes*/\n  proc sgplot data=mean_data NOAUTOLEGEND;\n    styleattrs datacontrastcolors=(red green blue) datacolors=(red green blue);\n    format cntry $country.;\n    scatter x=cntry y=&variable /group=cntry;\n  run;\n  \n%MEND;\n\n\n\nUsed plots\n\nGraphiques utilis√©s\n\n/*I.A.1*/\n    %panel_var1_var2(hinctnta,ditxssp,\"income\",\"gouv_evolution_impot_ps\",10,10);\n    %panel_var1_var2(hinctnta,sblazy,\"income\",\"presta_sociale\",10,5);\n    %panel_var1_var2(hinctnta,lbenent,\"income\",\"aides\",10,5);\n    %panel_var1_var2(hinctnta,insfben,\"income\",\"aides\",10,5);\n    \n/*I.A.2*/\n    %barres_stack(gvjbevn);\n    %barres_stack(gvhlthc);\n    %barres_stack(gvslvol);\n    %barres_stack(gvslvue);\n    %barres_stack(gvcldcr);\n    %barres_stack(gvpdlwk);\n    \n/*I.B*/\n    /*Acceptation*/\n        %trust(trstprl,ditxssp,10);\n        %trust(trstlgl,ditxssp,10);\n        %trust(trstplt,ditxssp,10);\n        %trust(trstprt,ditxssp,10);\n    /*M√©thode*/\n        %trust(trstprl,txearn,3);\n        %trust(trstlgl,txearn,3);\n        %trust(trstplt,txearn,3);\n        %trust(trstprt,txearn,3);\n    /*Efficacit√©*/\n        %trust(trstprl,txautef,10);\n        %trust(trstlgl,txautef,10);\n        %trust(trstplt,txautef,10);\n        %trust(trstprt,txautef,10);\n\n/*I.C*/\n    %consensus(\"gincdif\",\"presta_sociale\");\n    %consensus(\"sblwcoa\",\"presta_sociale\");\n    %consensus(\"txearn\",\"comment_taxer\");\n    %consensus(\"ipeqopt\",\"imp\");\n    %consensus(\"smdfslv\",\"presta_sociale\");\n    \n/*II.A*/\n    %panel_var1_var2(hinctnta,ditxssp,\"income\", \"gouv_evolution_impot_ps\",10,10);\n    \n/*II.B*/\n  %panel_var1_var2(edulvla,ditxssp,\"education_ISCED\", \"gouv_evolution_impot_ps\",10,10);\n\n/*II.C*/\n    %panel_var1_var2(agea,ditxssp,\"age\", \"gouv_evolution_impot_ps\",200,10);\n    \n/*III*/\n    %vari_en_fct_pays(imprich);\n    %vari_en_fct_pays(ipeqopt);\n    %vari_en_fct_pays(impfree);\n    %vari_en_fct_pays(iphlppl);\n    %vari_en_fct_pays(earnpen);\n    %vari_en_fct_pays(earnueb);\n    %vari_en_fct_pays(sblwlka);\n    %vari_en_fct_pays(sblazy);"
  },
  {
    "objectID": "projects/serie_temp/index.html",
    "href": "projects/serie_temp/index.html",
    "title": "Modelling a linear time series by an ARIMA model and prediction",
    "section": "",
    "text": "The selected series corresponds to the industrial production index (base 2021) in the sector of Woodworking and manufacture of wood and cork products, except furniture, manufacture of basketry and wickerwork products. It is characterized by a monthly frequency and covers the period from January 1990 to February 2025. This is a CVS-CJO index, which means that the series is adjusted for seasonal and working day variations, so it is already pre-processed to eliminate regular seasonal effects. INSEE - Monthly Data\nDownload PDF file.Download Report\n\n\nShow the report\n\nDownload PDF file.\n\n\n\nShow the code\n\n\n# Script avec commentaires pour le projet de s√©ries temporelles Paul / Mihnea\n# Premi√®re version: 01 Mai 2025 \n\n#==============================================================================#\n# Packages ---------------------------------------------------------------------\n#==============================================================================#\n\nlibrary(zoo)\nlibrary(tseries)\nlibrary(fUnitRoots)\nlibrary(purrr)\nlibrary(lmtest)\n\n#==============================================================================#\n# Partie 1 Les donn√©es ---------------------------------------------------------\n#==============================================================================#\n\n  #Importation et nettoyage de la base\ndata &lt;- read.csv(\"valeurs_mensuelles.csv\", sep = \",\")\ndata &lt;- data[-c(1:3), ] #Enlever les premi√®res lignes qui donnent l'ID de la base et la date de mise √† jour\ndata &lt;- data[,-c(3) ] #Enlever la derni√®re colonne avec les codes de chaque observation\ncolnames(data) &lt;- c(\"dates\",\"value\")\ndates_char &lt;- as.character(data$dates)\ndata$value &lt;- as.numeric(data$value)\ndates_char[[1]]; dates_char[length(dates_char)]\n\n[1] \"1990-01\"\n\n\n[1] \"2025-12\"\n\ndates &lt;- as.yearmon(seq(from=1990, to=2025+11/12, by=1/12))\nvalue &lt;- zoo(data$value, order.by=dates)\n\n  #Visualisation de la s√©rie temporelle et de son ACF\n\nplot(value)\n\n\n\n\n\n\n\nacf(value)\n\n\n\n\n\n\n\n      #La s√©rie ne pr√©sente pas de saisonnalit√© au vu de son √©volution et de son ACF.\n      #Cependant, graphiquement nous remarquons qu'elle n'est pas stationnaire.\n\n  #Diff√©renciation de la s√©rie et visualisation de dvalue\ndvalue &lt;- diff(value,1)\nplot(dvalue)\n\n\n\n\n\n\n\nacf(dvalue)\n\n\n\n\n\n\n\n      # La s√©rie diff√©renci√©e semble stationnaire et ne pr√©sente pas de saisonnalit√©\n      # Pas de signe visible √† l'oeil de tendance, donc a priori, la s√©rie n'est pas\n      # int√©gr√©e, i.e. n'a pas une racine unitaire.\n      # On va toutefois tester √ßa plus pr√©cis√©ment avec un test de racine unitaire \n\n  #Mod√®le de regression lin√©aire pour savoir quel test de racine unitaire faire\ndvalue &lt;- zoo(dvalue, order.by=dates)\nsummary(lm(dvalue ~ dates))\n\n\nCall:\nlm(formula = dvalue ~ dates)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-34.063  -2.131  -0.124   2.090  31.798 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) 17.592350  46.996939   0.374    0.708\ndates       -0.008821   0.023405  -0.377    0.706\n\nResidual standard error: 5.055 on 430 degrees of freedom\nMultiple R-squared:  0.0003302, Adjusted R-squared:  -0.001995 \nF-statistic: 0.142 on 1 and 430 DF,  p-value: 0.7064\n\n      #Au vu de la r√©gression lin√©aire, nous sommes dans le cas pas centr√© et pas de tendance visible\n      #On va alors effectuer un test de Perron-Phillips pour v√©rifier la pr√©sence ou non de racine unitaire\npptest_case_stationary &lt;- pp.test(dvalue, alternative = \"stationary\")\npptest_case_stationary$p.value\n\n[1] 0.01\n\n      #On obtient une p-value de 0.01 donc au seuil 98.9% on rejette H0 donc on accepte H1\n      #Dans le test de PP l'hypoth√®se H1 est \"il n'y a pas de racine unitaire\".\n      #On en conclu que la s√©rie diff√©renci√©e dvalue est stationnaire. Pour en √™tre s√ªr on peut faire un test de kpss\nkpss.test(dvalue, null = \"Level\")$p.value\n\n[1] 0.1\n\n      #La p-value obtenue est 0.1 donc au seuil 99% (m√™me 95%) on ne rejette pas H0 donc dvalue est bien stationnaire\n\n  #Repr√©sentation graphique de la s√©rie avant et apr√®s transformation\n#windows()\n#par(mfrow = c(2, 1))\nplot(value)\n\n\n\n\n\n\n\nplot(dvalue)\n\n\n\n\n\n\n\n#==============================================================================#\n# Partie 2 Mod√®les ARMA --------------------------------------------------------\n#==============================================================================#\n\n  #On commence par centrer la variable dvalue\ndvalue_centree &lt;- dvalue - mean(dvalue)\n\n  #On regarde l'ACF de cette nouvelle variable pour d√©terminer l'ordre maximal du c√¥t√© MA\nacf(dvalue_centree)\n\n\n\n\n\n\n\nq_test=2\n      #L'odre maximal du c√¥t√© MA est alors q_test = 2\n\n  #On regarde le PACF de cette nouvelle variable pour d√©terminer l'ordre maximal du c√¥t√© AR\npacf(dvalue_centree)\n\n\n\n\n\n\n\np_test=3\n      #L'odre maximal du c√¥t√© AR est alors p_test = 3\n\n  #Cr√©ation de la fonction de test Box-Ljung pour v√©rifier que les r√©sidus ne sont pas corr√©l√©s\nQtests &lt;- function(series, nb_lags_max_Portmanteau_test = 24, fitdf = 0) {\n  pvals &lt;- apply(X = matrix(1:nb_lags_max_Portmanteau_test), MARGIN = 1, \n                 FUN = function(l) {\n                   if (l &lt;= fitdf) {\n                     pval &lt;- NA\n                   } else {\n                     pval &lt;- Box.test(series, lag = l, type = \"Ljung-Box\", fitdf = fitdf)$p.value\n                   }\n                   return(c(\"lag\" = l, \"pval\" = pval))\n                 })\n  return(t(pvals))\n}\n\n  #On cr√©e tous les mod√®les possibles pour p&lt;=p_test et q&lt;=q_test\npqs &lt;- expand.grid(0:p_test,0:q_test)\nmat &lt;- matrix(NA, nrow=p_test +1, ncol=q_test +1)\nrownames(mat) &lt;- paste0(\"p=\",0:p_test) #renomme les lignes\ncolnames(mat) &lt;- paste0(\"q=\",0:q_test) #renomme les colonnes\nAICs &lt;- mat #matrice ou assigner les AIC\nBICs &lt;- mat #matrice ou assigner les BIC\nfor (row in 1:dim(pqs)[1]){\n  p &lt;- pqs[row,1]\n  q &lt;- pqs[row,2]\n  if ((p==0)&&(q==2)) {print(c(p,q))}\n  estim &lt;- arima(dvalue_centree,c(p,0,q), include.mean=F) #tente d'estimer l'ARIMA\n \n  q_tests = Qtests(estim$residuals, nb_lags_max_Portmanteau_test = 30, \n         fitdf = length(estim$coef))\n  if ((p==0)&&(q==2)) {print(q_tests)}\n  if ((p==0)&&(q==2)) {print(coeftest(estim))}\n  AICs[p+1,q+1] &lt;- if (class(estim)==\"try-error\") NA else estim$aic\n  BICs[p+1,q+1] &lt;- if (class(estim)==\"try-error\") NA else BIC(estim)\n}\n\n[1] 0 2\n      lag      pval\n [1,]   1        NA\n [2,]   2        NA\n [3,]   3 0.5524487\n [4,]   4 0.8336335\n [5,]   5 0.7997667\n [6,]   6 0.8927779\n [7,]   7 0.7102150\n [8,]   8 0.8155912\n [9,]   9 0.8853309\n[10,]  10 0.9255650\n[11,]  11 0.9285630\n[12,]  12 0.9342528\n[13,]  13 0.9439155\n[14,]  14 0.9210362\n[15,]  15 0.9066371\n[16,]  16 0.9380520\n[17,]  17 0.9202788\n[18,]  18 0.9461022\n[19,]  19 0.8702773\n[20,]  20 0.9037391\n[21,]  21 0.9272577\n[22,]  22 0.9447795\n[23,]  23 0.9615493\n[24,]  24 0.9036737\n[25,]  25 0.9262018\n[26,]  26 0.9431918\n[27,]  27 0.9473225\n[28,]  28 0.9574999\n[29,]  29 0.9694680\n[30,]  30 0.9739654\n\nz test of coefficients:\n\n     Estimate Std. Error z value  Pr(&gt;|z|)    \nma1 -0.307170   0.046560 -6.5973 4.187e-11 ***\nma2 -0.205355   0.046174 -4.4474 8.692e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n  #On d√©termine la validit√© des mod√®les\n\n      #Avec les tests du porte-manteau, on en d√©duit que les mod√®les o√π les r√©sidus sont bien d√©cor√©ll√©s au seuil 99% sont:\n        # ARMA( 3 , 0 ) ; ARMA( 1 , 1 ) ; ARMA( 2 , 1 ) ; ARMA( 3 , 1 ) ; ARMA( 0 , 2 ) ; ARMA( 1 , 2 ) ; ARMA( 2 , 2 ) ; ARMA( 3 , 2 ) ;\n      #AVec les tests de Student, on en d√©duit que les mod√®les o√π les coefficients de plus grand ordre sont significatifs sont:\n        # ARMA( 1 , 0 ) ; ARMA( 2 , 0 ) ; ARMA( 0 , 1 ) ; ARMA( 1 , 1 ) ; ARMA( 0 , 2 )\n\n      #Ainsi, les mod√®les possibles pour dvalue_centr√©e (ceux qui passent les deux tests de validit√©s) sont:\n        # ARMA( 1 , 1 ) ; ARMA( 0 , 2 )\n  \n  #On d√©termine les meilleurs mod√®les avec AIC , BIC\nAICs\n\n         q=0      q=1      q=2\np=0 2626.188 2594.061 2577.748\np=1 2609.066 2579.489 2579.379\np=2 2589.315 2579.415 2581.357\np=3 2584.691 2581.342 2582.358\n\n        #Au sens de AIC, le meilleur mod√®le est ARMA(0 , 2 )\nBICs\n\n         q=0      q=1      q=2\np=0 2630.256 2602.198 2589.953\np=1 2617.203 2591.694 2595.653\np=2 2601.520 2595.689 2601.699\np=3 2600.965 2601.684 2606.769\n\n        #Au sens de BIC, le meilleur mod√®le est ARMA( 0 , 2) \narima002 &lt;- arima(dvalue_centree, order = c(0, 0, 2), include.mean = FALSE)\narima101 &lt;- arima(dvalue_centree, order = c(1, 0, 1), include.mean = FALSE)\n\n  #On d√©termine le meilleur mod√®le parmi les deux pr√©c√©dants avec le crit√®re du R^2 ajust√©\n\nAdj_R2 &lt;- function(model){\n  p &lt;- model$arma[[1]] # ordre AR\n  q &lt;- model$arma[[2]] # ordre MA\n  ss_res &lt;- sum(model$residuals[-1]^2) # Modele ARMA sur dspread, perd premi√®re date\n  ss_tot &lt;- sum(dvalue_centree^2)\n  n &lt;- length(dvalue_centree)\n  adj_r2 &lt;- 1 - (ss_res / (n - (p + q + 1))) / (ss_tot / (n - 1))\n  return(adj_r2)\n}\nAdj_R2(arima101)\n\n[1] 0.110115\n\nAdj_R2(arima002)\n\n[1] 0.1136935\n\n      #Au sens du crit√®re du R^2, le meilleur mod√®le est ARMA( 0 , 2 )\n\n#### Par cons√©quent, le meilleur mod√®le pour value est ARIMA(0,1,2)\nvalue &lt;- value\nmodel &lt;- arima(value,c(0,1,2), include.mean=F)\n\n#==============================================================================#\n# Partie 3 Pr√©diction ----------------------------------------------------------\n#==============================================================================#\n\n#Avec le mod√®le ARIMA(0,1,2), la pr√©diction devenait constante √† partir de l'horizon 2\n#Ainsi, on a chois de prendre l'autre mod√®le valide √† savoir le mod√®le ARIMA(1,1,1)\n\n#Avoir le theta, le phi et le sigma avec le mod√®le ARIMA(1,1,1)\nsigma2 &lt;- arima101$sigma2\nphi &lt;- coef(arima101)[\"ar1\"]  \ntheta &lt;- coef(arima101)[\"ma1\"]  \n\n#Fixer les param√®tres de la pr√©diction\nn_value &lt;- length(value)\nhorizon &lt;- 5\nstart_pred &lt;- n_value - horizon\nvalue_vraie &lt;- as.numeric(value)\n\n#Effectuer la pr√©diction\nfit &lt;- arima(value_vraie[1:(n_value - horizon)], order = c(1, 1, 1))\n \nprediction &lt;- function(phi, theta, value_vraie, start_pred, horizon) {\n  val1 &lt;- value_vraie[start_pred]   #t_X_t                          \n  val2 &lt;- val1 + phi * (val1 - value_vraie[start_pred - 1]) \n  var_vec &lt;- numeric(horizon + 1)\n  #t_X_t+1\n  var_vec[1]  &lt;- val1 \n  var_vec[2]  &lt;- val2 \n  # Calculer les valeurs pour h = 2 √† horizon\n  for (h in 2:horizon) {\n    var_vec[h+1] &lt;- (1 / (1 - phi)) * (val2 - phi * val1 + (val1 - val2) * phi^h) #t_X_t+h\n  } \n  # Retourner le vecteur complet\n  return(var_vec)\n}\n#Calculer la variance des √©carts\nvariance &lt;- function(phi, theta, sigma2, horizon) {\n  # Initialise vecteur r√©sultats\n  var_vec &lt;- numeric(horizon + 1)\n  var_vec[1] &lt;- 0  # pour h=0\n  \n  for (h in 1:horizon) {\n    sum_k &lt;- 0\n    for (k in 0:(h-1)) {\n      val_k &lt;- (1 - phi^(k+1) + theta + theta * phi^k) / (1 - phi)\n      sum_k &lt;- sum_k + val_k^2\n    }\n    var_vec[h+1] &lt;- sigma2 * sum_k\n  }\n  \n  return(var_vec)\n}\n\n#Cr√©er la base avec toutes les infos de la pr√©dition\n\npred &lt;- data.frame(\n  pred = prediction(phi, theta, value_vraie, start_pred, horizon),\n  se = variance(phi, theta, sigma2, horizon))\n\n\n# Cr√©er la s√©rie pr√©dite et la s√©rie des bornes de l'intervalle de confiance\npredicted_values &lt;- ts(pred$pred, start = start_pred)\nlower_95 &lt;- ts(pred$pred - 1.96 * pred$se, start = start_pred)\nupper_95 &lt;- ts(pred$pred + 1.96 * pred$se, start = start_pred)\n\n# Tracer la s√©rie originale et les pr√©dictions\nplot(value_vraie, type=\"l\", xlim = c(n_value - 2 * horizon, n_value), ylim = range(c(value_vraie[(n_value - 2*horizon):n_value], lower_95, upper_95)+c(-10,10), na.rm = TRUE), #Enlever le lower_95 et le upper_95 pour une meilleur fen√™tre\n     col = \"black\", lwd = 2, main = \"Pr√©vision ARIMA(1,1,1) pour les derni√®res valeurs\",\n     ylab = \"Valeur\", xlab = \"Temps\")\n\n# Ajouter les pr√©dictions et les intervalles\nlines(predicted_values, col = \"blue\", lwd = 2)\nlines(lower_95, col = \"red\", lty = 2)\nlines(upper_95, col = \"red\", lty = 2)\n\nlegend(\"topleft\", legend = c(\"S√©rie r√©elle\", \"Pr√©diction\", \"Intervalle 95%\"),\n       col = c(\"black\", \"blue\", \"red\"), lty = c(1,1,2), lwd = 2)\n\n\n\n\n\n\n\n# Tracer la s√©rie originale et les pr√©dictions\nplot(value_vraie, type=\"l\", xlim = c(n_value - 2 * horizon, n_value), ylim = range(c(value_vraie[(n_value - 2*horizon):n_value])+c(-10,10), na.rm = TRUE), #Enlever le lower_95 et le upper_95 pour une meilleur fen√™tre\n     col = \"black\", lwd = 2, main = \"Pr√©vision ARIMA(1,1,1) pour les derni√®res valeurs\",\n     ylab = \"Valeur\", xlab = \"Temps\")\n\n# Ajouter les pr√©dictions et les intervalles\nlines(predicted_values, col = \"blue\", lwd = 2)\nlines(lower_95, col = \"red\", lty = 2)\nlines(upper_95, col = \"red\", lty = 2)\n\nlegend(\"topleft\", legend = c(\"S√©rie r√©elle\", \"Pr√©diction\", \"Intervalle 95%\"),\n       col = c(\"black\", \"blue\", \"red\"), lty = c(1,1,2), lwd = 2)"
  },
  {
    "objectID": "projects/fiscalite/index.html#part-1-import-the-ess-data",
    "href": "projects/fiscalite/index.html#part-1-import-the-ess-data",
    "title": "Thesis on descriptive statistics on taxation in France",
    "section": "Part 1: Import the ESS data",
    "text": "Part 1: Import the ESS data\n\n\nImport the data with the chosen variables\n\nCr√©ation de la libraire o√π se situe la base de donn√©es\nlibname ess \"W:\\Telechargements\";\nImportation de la base de donn√©es avec les variables retenues\ndata ess;\nset ess.ess;\nkeep \ncntry /*Country*/\ngincdif /*Government should reduce differences in income levels (opinion)*/\nagea /*Age of respondent, calculated*/\nhinctnta /*Household's total net income, all sources*/\nsmdfslv /*For fair society, differences in standard of living should be small*/\nsblazy /*Social benefits/services make people lazy*/\nsblwcoa /*Social benefits/services make people less willing care for one another*/\nsblwlka /*Social benefits/services make people less willing look after themselves/family*/\ntxautef /*Tax authorities, how efficient in doing their job*/\nditxssp /*Government decrease/increase taxes and social spending*/\ntxearn /*Taxation for higher versus lower earners*/\nearnpen /*Higher or lower earners should get larger old age pensions*/\nearnueb /*Higher or lower earners should get larger unemployment benefits*/\nlbenent /*Many with very low incomes get less benefit than legally entitled to*/\ninsfben /*Insufficient benefits in country to help people in real need*/\ntrstprl /*Trust in country's parliament*/\nedulvla /*Highest level of education*/\ntrstlgl /*Trust in the legal system*/\ntrstplt /*Trust in politicians*/\ntrstprt /*Trust in political parties*/\nimprich /*Important to be rich, have money and expensive things*/\nipeqopt /*Important that people are treated equally and have equal opportunities*/\nimpfree /*Important to make own decisions and be free*/\niphlppl /*Important to help people and care for others well-being*/\ngvjbevn /*Job for everyone, governments' responsibility*/\ngvhlthc /*Health care for the sick, governments' responsibility*/\ngvslvol /*Standard of living for the old, governments' responsibility*/\ngvslvue /*Standard of living for the unemployed, governments' responsibility*/\ngvcldcr /*Child care services for working parents, governments' responsibility*/\ngvpdlwk /*Paid leave from work to care for sick family, governments' responsibility*/;\nRUN;"
  },
  {
    "objectID": "projects/fiscalite/index.html#part-2-setup-of-the-variables",
    "href": "projects/fiscalite/index.html#part-2-setup-of-the-variables",
    "title": "Thesis on descriptive statistics on taxation in France",
    "section": "Part 2: Setup of the variables",
    "text": "Part 2: Setup of the variables\n\n\nAdd labels to the variables\n\nRenommage des variables avec des labels\ndata ess_label;\nset ess;\nlabel\ncntry = \"Pays de r√©sidence\"\nagea = \"Age\"\ngincdif = \"Le gouvernement doit prendre des mesures pour r√©duire les in√©galit√©s de revenu (1 = D'accord et 5 = Pas d'accord)\"\nhinctnta = \"Revenu\"\nsmdfslv = \"Pour une soci√©t√© juste, les diff√©rences de niveau de vie doivent √™tre faibles (1 = D'accord et 5 = Pas d'accord)\"\nsblazy = \"Les prestations sociales et les services sociaux rendent les personnes paresseuses (1 = Totalement d'accord et 5 = Totalement pas d'accord)\"\nsblwcoa = \"Les prestations sociales et les services sociaux conduisent les personnes √† moins prendre soin des autres (1 = Totalement d'accord et 5 = Totalement pas d'accord)\"\nsblwlka = \"Les prestations sociales et les services sociaux conduisent les personnes √† moins prendre soin de leurs proches (1 = Totalement d'accord et 5 = Totalement pas d'accord)\"\ntxautef = \"Les autorit√©s fiscales sont efficaces (10 = Tr√®s efficaces)\"\nditxssp = \"Il faut augmenter les imp√¥ts et les prestations sociales \"\ntxearn = \"Impots proportionnels (1), progressifs (2) ou √©gal (3) ?\"\nearnpen = \"Retraite en fonction du salaire (1 = Riche retraite plus √©lev√©e, 2 = Retraite √©gale et 3 = Riche retraite moins √©lev√©e\"\nearnueb = \"Les hauts salaires doivent-ils avoir une aide au ch√¥mage plus √©lev√©e (1), √©gale (2) ou moins √©lev√©e (3) ?\"\nlbenent = \"Beaucoup de personnes √† tr√®s faible revenu per√ßoivent moins d'aides que ce dont ils ont acc√®s\"\ntrstprl = \"Avez-vous confiance dans votre parlement ? (0 = Pas confiance et 10 = Confiance)\"\nedulvla = \"Niveau √©ducation maximal\"\ntrstlgl = \"Confiance dans le syst√®me l√©gal\"\ntrstplt = \"Confiance dans les politiciens\"\ntrstprt = \"Confiance dans les partis politiques\"\nimprich = \"Importance d'√™tre riche (1=Oui et 6=Non)\"\nipeqopt = \"Importance d'√™tre √©gaux (1=Oui et 6=Non)\"\nimpfree = \"Importance d'√™tre libre (1=Oui et 6=Non)\"\niphlppl = \"Importance d'aider les autres (1=Oui et 6=Non)\"\ngvjbevn = \"Responsabilit√© du gouvernement pour les emplois pour tous\"\ngvhlthc = \"Resp du gouv pour le syst√®me de sant√©\"\ngvslvol = \"Resp du gouv pour le niveau de vie des personnes √¢g√©es\"\ngvslvue = \"Resp du gouv pour le niveau de vie des ch√¥meurs\"\ngvcldcr = \"Resp du gouv pour le soin aux enfants de travailleurs\"\ngvpdlwk = \"Resp du gouv jour off pay√© afin de prendre soin famille malade\";\nRUN;\n\n\n\nAdd formats to the variables\n\nCr√©ation de formats\n\nPROC FORMAT;\nvalue income\n1-5 = \"Classe populaire et moyenne inf√©rieure\"\n6-8 = \"Classe moyenne\"\n9-10 = \"Classe sup√©rieure\"\n77 = \"A refus√© de r√©pondre\"\n88 = \"Ne sais pas\"\n99 = \"Pas de r√©ponse\";\nrun;\n\nPROC FORMAT;\nvalue age\n0-&lt;15 = \"Enfant ou adolescent\"\n15-&lt;30 = \"Moins de 30 ans\"\n30-65 = \"Entre 30 et 65 ans\"\n65-500 = \"Plus de 65 ans\"\n999 = \"Pas de r√©ponse\";\nRUN;\n\nPROC FORMAT;\nvalue $country\n\"DK\",\"SE\",\"NO\",\"FI\" = \"Mod√®le Social-D√©mocrate\"\n\"FR\",\"BE\",\"LU\",\"DE\",\"AT\" = \"Mod√®le Conservateur/Corporatiste\"\n\"GB\",\"CY\",\"IE\"=\"Mod√®le Lib√©ral\"\n\"AL\",\"HR\",\"ME\",\"MK\",\"SI\",\"XK\",\"SK\",\"CH\",\"NL\",\"GE\",\"IL\",\"TR\",\"EE\",\"IS\",\"RO\",\"RS\",\"BG\",\n\"CZ\",\"HU\",\"PL\",\"RU\",\"UA\",\"LV\",\"LT\",\"ES\",\"IT\",\"GR\",\"PT\" = \"Autre\";\nRUN;\n\nPROC FORMAT;\nvalue presta_sociale\n1 = \" Absolument d'accord\"\n2 = \"Plut√¥t d'accord\"\n3 = \"Indiff√©rent\"\n4 = \"Plut√¥t pas d'accord\"\n5 = \"Absolument pas d'accord\"\n7 = \"A refus√© de r√©pondre\"\n8 = \"Ne sais pas\"\n9 = \"Pas de r√©ponse\";\nrun;\n\nPROC FORMAT;\nvalue resp_gouv\n0-2 = \"Absolument pas d'accord\"\n3-4 = \"Plut√¥t pas d'accord\"\n5 = \"Sans opinion\"\n6-7 = \"Plut√¥t d'accord\"\n8-10 = \"Absolument d'accord\"\n77 = \"A refus√© de r√©pondre\"\n88 = \"Ne sais pas\"\n99 = \"Pas de r√©ponse\";\nRUN;\n\nPROC FORMAT;\nvalue gouv_evolution_impot_ps\n0-2 = \"Absolument pas d'accord\"\n3-4 = \"Plut√¥t pas d'accord\"\n5 = \"Sans opinion\"\n6-7 = \"Plut√¥t d'accord\"\n8-10 = \"Absolument d'accord\"\n77 = \"A refus√© de r√©pondre\"\n88 = \"Ne sais pas\"\n99 = \"Pas de r√©ponse\";\nRUN;\n\nPROC FORMAT;\nvalue aides\n1 = \"Absolument d'accord\"\n2 = \"Plut√¥t d'accord\"\n3 = \"Indiff√©rent\"\n4 = \"Plut√¥t pas d'accord\"\n5 = \"Absolument pas d'accord\"\n7 = \"A refus√© de r√©pondre\"\n8 = \"Ne sais pas\"\n9 = \"Pas de r√©ponse\";\nRUN;\n\nPROC FORMAT;\nvalue comment_taxer\n1 = \"Imp√¥t proportionnel\"\n2 = \"Imp√¥t progressif\"\n3 = \"Imp√¥t √©gal\"\n4 = \"Aucun de ces r√©ponse\"\n7 = \"A refus√© de r√©pondre\"\n8 = \"Ne sais pas\"\n9 = \"Pas de r√©ponse\";\nRUN;\n\nPROC FORMAT;\nvalue education_ISCED\n0 = \"Impossible d'harmoniser\"\n1 = \"Moins que secondaire\"\n2-3 = \"Secondaire\"\n4-5 = \"Sup√©rieur\"\n55 = \"Autre\"\n77 = \"A refus√© de r√©pondre\"\n88 = \"Ne sais pas\"\n99 = \"Pas de r√©ponse\";\nRUN;\n\nPROC FORMAT;\nvalue gouv\n0-3 = \"Pas d'accord\"\n4-6 = \"Sans opinion\"\n7-10 = \"D'accord\"\n77 = \"A refus√© de r√©pondre\"\n88 = \"Ne sais pas\"\n99 = \"Pas de r√©ponse\";\nRUN;\n\nPROC FORMAT;\nvalue imp\n0-2 = \"Important\"\n2-4 = \"Neutre\"\n4-6 = \"Pas important\"\n7 = \"A refus√© de r√©pondre\"\n8 = \"Ne sais pas\"\n9 = \"Pas de r√©ponse\";\nRUN;"
  },
  {
    "objectID": "projects/fiscalite/index.html#part-3-make-the-plots",
    "href": "projects/fiscalite/index.html#part-3-make-the-plots",
    "title": "Thesis on descriptive statistics on taxation in France",
    "section": "Part 3: Make the plots",
    "text": "Part 3: Make the plots\n\n\nCreate function for the plots\n\nCr√©ation des macros que l‚Äôon va utiliser\n\n%MACRO panel_var1_var2(variable1,variable2,format1,format2,maxvar1,maxvar2);/*Cette macro cr√©e un panneau suivant les valeurs d'une variable \"variable1\" cod√©e par le format \"format1\" et dans chaque case du panneau repr√©sente les proportions des valeurs de la variable \"variable2\" cod√©e par le format \"format2\"*/\n\n  /*Tri de la table suivant la variable \"variable1\"*/\n  proc sort data=ess_label;\n    by &variable1;\n  run;\n  /*Calcul des pourcentages de chaque valeur de la variable \"variable2\" en groupant selon les valeurs de la variable \"variable1\"*/\n  proc freq data=ess_label\n  (WHERE = (cntry=\"FR\" and &variable1&lt;=&maxvar1 and &variable2&lt;=&maxvar2))\n  noprint;\n    format &variable1 %scan(&format1, 1, %str(%bquote(%')%str(%\"))).;\n    by &variable1;\n    tables &variable2 / out=FreqOut;\n  run;\n  \n  /*Cr√©ation du panneau suivant les valeurs de la variable \"variable1\" en repr√©sentant les proportions des valeurs de la variable \"variable2\" */\n  proc sgpanel data=FreqOut;\n    format &variable1 %scan(&format1, 1, %str(%bquote(%')%str(%\"))).;\n    format &variable2 %scan(&format2, 1, %str(%bquote(%')%str(%\"))).;\n    styleattrs datacontrastcolors=(red green blue) datacolors=(red green blue);\n    panelby &variable1 / columns = 3 novarname noheader;\n    vbar &variable2 /group=&variable1 barwidth=0.5\n  response=percent datalabel ;\n  run;\n  \n%MEND;\n\n\n%MACRO barres_stack(variable);/*Cette macro permet pour une variable \"variable\", qui sera une variable de responsabilit√© du gouvernement, de faire un histogramme horizontal avec barres empil√©es pour repr√©senter cette variable pour les diff√©rentes classes de revenu*/\n\n  /*Tri de la table suivant le revenu avec les observations utiles*/\n  proc sort data=ess_label (WHERE=(cntry= \"FR\" and hinctnta&lt;=10 and &variable&lt;=10 )) out=ess_label_bis ;\n    format hinctnta income.;\n    by hinctnta;\n  run;\n  \n  /*Calcul des pourcentages de chaque valeur de la variable \"variable\" en groupant selon les classes de revenu*/\n\n  proc freq data=ess_label_bis noprint;\n    by hinctnta;\n    tables &variable / out=FreqOut;\n  run;\n  \n  /*Cr√©ation de l'histogramme horizontal avec barres empil√©es*/\n  proc sgplot data=FreqOut NOAUTOLEGEND;\n    styleattrs datacontrastcolors=(red green blue) datacolors=(red green blue);\n    format hinctnta income.;\n    format &variable gouv.;\n    hbar hinctnta / response=Percent group=&variable groupdisplay=stack barwidth=0.5 ;\n    xaxis grid values=(0 to 100 by 10);\n  run;\n  \n%MEND;\n\n\n%MACRO trust(variable1,variable2,maxvar2); /*Cette macro √©tudie le lien entre diff√©rentes variables de confiances \"variable1\" en abscisse et \"variable2\" en ordonn√©es. Elle fait une moyenne sur les pays et repr√©sente une droite de tendance*/\n\n  /*Calcule la moyenne de la variable \"variable1\" pour chaque pays*/\n  proc means data=ess_label (where = (&variable2 &lt;=&maxvar2 and &variable1&lt;50)) noprint;\n    class cntry;\n    var &variable1 &variable2 ;\n    output out=mean_data_2 mean=;\n  run;\n  /*Repr√©sente en abscisses la variable \"variable1\" et en ordonn√©e \"variable2\" avec la droite de tendance*/\n  proc sgplot data=mean_data_2;\n    scatter x=&variable1 y=&variable2 / group=cntry;\n    keylegend / location=outside;\n    reg x=&variable1 y=&variable2 / lineattrs=(color=red) NOMARKERS;\n  run;\n%MEND;\n\n\n%MACRO consensus(variable, format); /*Cette macro √©tudie les fr√©quences de la variable \"variable\" cod√©e par le format \"format\" pour voir s'il existe un consensus aupr√®s des individus*/\n\n  /*Calcul des fr√©quences des valeurs de la variable \"variable\"*/\n  proc freq data=ess_label (WHERE=(cntry=\"FR\" /*and 8&lt;=hinctnta&lt;=10 Pour le dernier consensus */ ));\n    tables %scan(&variable, 1, %str(%bquote(%')%str(%\"))) / out=FreqOut;\n  run;\n  \n/*Cr√©ation del'histogramme pour voir s'il existe un consensus*/\n  proc sgplot data=FreqOut NOAUTOLEGEND;\n    styleattrs datacontrastcolors=(red orange green blue purple red) datacolors=(red orange green blue purple red);\n    VBAR %scan(&variable, 1, %str(%bquote(%')%str(%\"))) /response=percent group=%scan(&variable, 1, %str(%bquote(%')%str(%\")))\n    datalabel; format %scan(&variable, 1, %str(%bquote(%')%str(%\")))\n%scan(&format, 1, %str(%bquote(%')%str(%\"))).;\n  run;\n  \n%MEND;\n\n%MACRO vari_en_fct_pays(variable);/*Cette macro cr√©e un graphique de points avec en abscisse la cat√©gorie de pays (Europe Centrale, Europe du Nord, Lib√©ral, Familialiste) et en ordonn√©e la moyenne de la variable \"variable\" pour chaque pays de chaque cat√©gorie*/\n\n  /*Renvoit la moyenne de la variable \"variable\" pour chaque pays pr√©sent dans la table */\n  proc means data=ess_label (where = (&variable&lt;=4)) noprint;\n    class cntry;\n    var &variable;\n    output out=mean_data mean=;\n  run;\n  /*Selectionne les moyennes qui correspondent aux pays des diff√©rentes cat√©gories √©tudi√©es*/\n  data mean_data;\n    set mean_data;\n    if cntry in (\"DK\",\"SE\",\"NO\",\"FI\",\"FR\",\"BE\",\"LU\", \"DE\",\"AT\",\"GB\",\"CY\",\"IE\");\n  run;\n/*Cr√©ation du graphique de points en regroupant par la cat√©gorie de pays afin d'obtenir des couleurs diff√©rentes*/\n  proc sgplot data=mean_data NOAUTOLEGEND;\n    styleattrs datacontrastcolors=(red green blue) datacolors=(red green blue);\n    format cntry $country.;\n    scatter x=cntry y=&variable /group=cntry;\n  run;\n  \n%MEND;\n\n\n\nUsed plots\n\nGraphiques utilis√©s\n\n/*I.A.1*/\n    %panel_var1_var2(hinctnta,ditxssp,\"income\",\"gouv_evolution_impot_ps\",10,10);\n    %panel_var1_var2(hinctnta,sblazy,\"income\",\"presta_sociale\",10,5);\n    %panel_var1_var2(hinctnta,lbenent,\"income\",\"aides\",10,5);\n    %panel_var1_var2(hinctnta,insfben,\"income\",\"aides\",10,5);\n    \n/*I.A.2*/\n    %barres_stack(gvjbevn);\n    %barres_stack(gvhlthc);\n    %barres_stack(gvslvol);\n    %barres_stack(gvslvue);\n    %barres_stack(gvcldcr);\n    %barres_stack(gvpdlwk);\n    \n/*I.B*/\n    /*Acceptation*/\n        %trust(trstprl,ditxssp,10);\n        %trust(trstlgl,ditxssp,10);\n        %trust(trstplt,ditxssp,10);\n        %trust(trstprt,ditxssp,10);\n    /*M√©thode*/\n        %trust(trstprl,txearn,3);\n        %trust(trstlgl,txearn,3);\n        %trust(trstplt,txearn,3);\n        %trust(trstprt,txearn,3);\n    /*Efficacit√©*/\n        %trust(trstprl,txautef,10);\n        %trust(trstlgl,txautef,10);\n        %trust(trstplt,txautef,10);\n        %trust(trstprt,txautef,10);\n\n/*I.C*/\n    %consensus(\"gincdif\",\"presta_sociale\");\n    %consensus(\"sblwcoa\",\"presta_sociale\");\n    %consensus(\"txearn\",\"comment_taxer\");\n    %consensus(\"ipeqopt\",\"imp\");\n    %consensus(\"smdfslv\",\"presta_sociale\");\n    \n/*II.A*/\n    %panel_var1_var2(hinctnta,ditxssp,\"income\", \"gouv_evolution_impot_ps\",10,10);\n    \n/*II.B*/\n  %panel_var1_var2(edulvla,ditxssp,\"education_ISCED\", \"gouv_evolution_impot_ps\",10,10);\n\n/*II.C*/\n    %panel_var1_var2(agea,ditxssp,\"age\", \"gouv_evolution_impot_ps\",200,10);\n    \n/*III*/\n    %vari_en_fct_pays(imprich);\n    %vari_en_fct_pays(ipeqopt);\n    %vari_en_fct_pays(impfree);\n    %vari_en_fct_pays(iphlppl);\n    %vari_en_fct_pays(earnpen);\n    %vari_en_fct_pays(earnueb);\n    %vari_en_fct_pays(sblwlka);\n    %vari_en_fct_pays(sblazy);"
  },
  {
    "objectID": "interview_questions/project1/index.html",
    "href": "interview_questions/project1/index.html",
    "title": "Brainteasers",
    "section": "",
    "text": "Let‚Äôs discover some interview questions labelled as brain teasers\n\n\n\n\n\n\n\n\n\n\n\n\nBrainteaser 1\n\n\n\n\n\n\nMihnea POPA\n\n\n\n\n\n\n\n\n\n\n\nBrainteaser 2\n\n\n\n\n\n\nMihnea POPA\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "interview_questions/project1/index.html#sub-header",
    "href": "interview_questions/project1/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "interview_questions.html",
    "href": "interview_questions.html",
    "title": "My Interview questions",
    "section": "",
    "text": "Brainteasers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbabilities\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "interview_questions/project2/index.html",
    "href": "interview_questions/project2/index.html",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Let‚Äôs investigate the relationship between fuel efficiency (mpg) and engine displacement (disp) from the mtcars dataset. Those variables have a correlation of -0.85.\n\n\nHere is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "interview_questions/project2/index.html#sub-header",
    "href": "interview_questions/project2/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "interview_questions/project1/brainteaser/2/index.html",
    "href": "interview_questions/project1/brainteaser/2/index.html",
    "title": "Brainteaser 2",
    "section": "",
    "text": "Second problem"
  },
  {
    "objectID": "interview_questions/project1/brainteaser/1/index.html",
    "href": "interview_questions/project1/brainteaser/1/index.html",
    "title": "Brainteaser 1",
    "section": "",
    "text": "First problem"
  },
  {
    "objectID": "interview_questions/brainteasers/brainteaser/2/index.html",
    "href": "interview_questions/brainteasers/brainteaser/2/index.html",
    "title": "Brainteaser 2",
    "section": "",
    "text": "Second problem"
  },
  {
    "objectID": "interview_questions/brainteasers/brainteaser/1/index.html",
    "href": "interview_questions/brainteasers/brainteaser/1/index.html",
    "title": "Brainteaser 1",
    "section": "",
    "text": "First problem"
  },
  {
    "objectID": "interview_questions/brainteasers/index.html",
    "href": "interview_questions/brainteasers/index.html",
    "title": "Brainteasers",
    "section": "",
    "text": "Let‚Äôs discover some interview questions labelled as brain teasers\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinding a lighter coin with minimum weightings\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeasuring time with burning ropes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinding the fastest horses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAvoiding prisoners escape\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDetermining the angle at 3:15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCube explosion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFallen eggs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisened Wine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWind effect on a plane\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating 2 groups with equal heads\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCounting squares in a grid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCrossing a bridge in minimum time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputing ratio speed on a circular track\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrisoners random hat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAverage Speed of a train travel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWine in water or water in wine ?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPolyglots in society\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCatching a furtive spy\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "interview_questions/brainteasers/2.html",
    "href": "interview_questions/brainteasers/2.html",
    "title": "Brainteaser 2",
    "section": "",
    "text": "Second problem"
  },
  {
    "objectID": "interview_questions/brainteasers/1.html",
    "href": "interview_questions/brainteasers/1.html",
    "title": "Measuring time with burning ropes",
    "section": "",
    "text": "Let‚Äôs suppose that we have two ropes and each takes one hour to burn but not uniformly. How can we measure 45 minutes ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nTry to think about everything that you can do with the ropes and the lighter.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nAt \\(t=0 \\text{min}\\), we burn one end of the first rope and the two ends of the second rope\n\\[\n\\begin{aligned}\n&üî• \\rule{2cm}{0.4pt} \\\\\n&üî• \\rule{2cm}{0.4pt}üî•\n\\end{aligned}\n\\] After a half-hour, so at \\(t=30 \\text{min}\\), the second rope has entirely burned and the first one has a remaining of 30 minutes. At this time, we burn the second end of the first rope.\n\\[\n\\begin{aligned}\n& \\rule{0.5cm}{0.01pt}üî• \\rule{1.5cm}{0.4pt}üî• \\\\\n& \\rule{0.5cm}{0.01pt}üî• \\rule{0cm}{0.4pt}üî•\n\\end{aligned}\n\\] Finally, the remaining part of the first rope takes 30 minutes to burn but if we burn at both ends, it only takes 15 minutes. Therefore at \\(t=45 \\text{min}\\), the first rope will also be burned entirely. \\[\n\\begin{aligned}\n& \\rule{1.25cm}{0.01pt}üî• \\rule{0.75cm}{0.4pt}üî• \\\\\n& \\rule{0.5cm}{0.01pt}üî• \\rule{0cm}{0.4pt}üî•\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "interview_questions/probabilities/2.html",
    "href": "interview_questions/probabilities/2.html",
    "title": "Brainteaser 2",
    "section": "",
    "text": "Second problem"
  },
  {
    "objectID": "interview_questions/probabilities/1.html",
    "href": "interview_questions/probabilities/1.html",
    "title": "Brainteaser 1",
    "section": "",
    "text": "First problem"
  },
  {
    "objectID": "interview_questions/probabilities/index.html",
    "href": "interview_questions/probabilities/index.html",
    "title": "Probabilities",
    "section": "",
    "text": "Let‚Äôs discover some interview questions labelled as probabilities\n\n\n\n\n\n\n\n\n\n\n\n\n\nBrainteaser 1\n\n\n\n\n\n\nMihnea POPA\n\n\n\n\n\n\n\n\n\n\n\nBrainteaser 2\n\n\n\n\n\n\nMihnea POPA\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "interview_questions/brainteasers/time_burning_ropes.html",
    "href": "interview_questions/brainteasers/time_burning_ropes.html",
    "title": "Measuring time with burning ropes",
    "section": "",
    "text": "Let‚Äôs suppose that we have two ropes and each takes one hour to burn but not uniformly. How can we measure 45 minutes ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nTry to think about everything that you can do with the ropes and the lighter.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nAt \\(t=0 \\text{min}\\), we burn one end of the first rope and the two ends of the second rope\n\\[\n\\begin{aligned}\n&üî• \\rule{2cm}{0.4pt} \\\\\n&üî• \\rule{2cm}{0.4pt}üî•\n\\end{aligned}\n\\] After a half-hour, so at \\(t=30 \\text{min}\\), the second rope has entirely burned and the first one has a remaining of 30 minutes. At this time, we burn the second end of the first rope.\n\\[\n\\begin{aligned}\n& \\rule{0.5cm}{0.01pt}üî• \\rule{1.5cm}{0.4pt}üî• \\\\\n& \\rule{0.5cm}{0.01pt}üî• \\rule{0cm}{0.4pt}üî•\n\\end{aligned}\n\\] Finally, the remaining part of the first rope takes 30 minutes to burn but if we burn at both ends, it only takes 15 minutes. Therefore at \\(t=45 \\text{min}\\), the first rope will also be burned entirely. \\[\n\\begin{aligned}\n& \\rule{1.25cm}{0.01pt}üî• \\rule{0cm}{0.4pt}üî• \\\\\n& \\rule{0.5cm}{0.01pt}üî•  \\rule{0cm}{0.4pt}üî•\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "interview_questions/brainteasers/unique_ligher_coin.html",
    "href": "interview_questions/brainteasers/unique_ligher_coin.html",
    "title": "Finding a ligher coin with minimum weightings",
    "section": "",
    "text": "Let‚Äôs suppose that we have 100 coins but one is ligher that the others. Find the minimum number of weightings to identify this fake coin.\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nTry to think about how many outcomes can one weighting differentiate.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nEach weighing can lead to three different outcomes:\n\nThe left part is heavier\nThe left part is lighter\nThe left part and the right part have same weight\n\nNow we can find the strategy:\n\nFirst weighting : 33 vs 33 (34 left)\nSecond weighting:\n\nIf one of the groups was lighter: 11 vs 11 (11 left)\nIf same weight: 11 vs 11 (12 left)\n\nThird weighting:\n\nIf the second case led to same weight : 4 vs 4 (4 left)\nIf not: 4 vs 4 (3 left)\n\nFourth weighting:\n\nIf the second case led to same weight: 1 vs 1 (1 left) ‚úÖ\nIf not : 1 vs 1 (2 left)\n\nFifth weighting:\n\nIf the second case led to different weights: ‚úÖ\nIf not : 1 vs 1 (0 left) ‚úÖ\n\n\nSo the minimum number of weighting to be sure to identify the fake coin in n = 5.\n\n\n\n\n\n\n\n\n\nTipüö® Generalisation\n\n\n\n\n\nWe can try to generalise this strategy. Let‚Äôs assume that there are \\(N\\) coins with one fake. Then since each weighting leads to \\(3\\) different outcomes, we can identify the fake coins with \\(n\\) weightings if \\(3^n&gt;N\\). We want the minimum number of weightings to be sure to identify the coin, thus \\[3^{n-1}&lt;N \\le 3^n.\\] Accordingly, we have \\[n = \\lfloor \\frac {ln(N)}{ln(3)} \\rfloor + 1 .\\] With \\(N=100\\), we find indeed \\(n=5\\)."
  },
  {
    "objectID": "interview_questions/brainteasers/horse_race.html",
    "href": "interview_questions/brainteasers/horse_race.html",
    "title": "Finding the fastest horses",
    "section": "",
    "text": "Let‚Äôs suppose that we have 25 horses and we can race 5 horses at a time. What is the minimum number of races to identify the 3 fastest horses ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nWe can put them in five groups of 5 horses and within a group we will know the order. But how can we order them across the groups ?\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nWe start by separating the horses into five different groups and we run a race in each group. By symmetry we can denote by A, B, C, D and E the groups and by the indexes corresponding to their order. Therefore, we have \\[\n\\begin{aligned}\n& A_1 &lt; A_2 &lt; A_3 &lt; A_4 &lt; A_5 \\\\\n& B_1 &lt; B_2 &lt; B_3 &lt; B_4 &lt; B_5 \\\\\n& C_1 &lt; C_2 &lt; C_3 &lt; C_4 &lt; C_5 \\\\\n& D_1 &lt; D_2 &lt; D_3 &lt; D_4 &lt; D_5 \\\\\n& E_1 &lt; E_2 &lt; E_3 &lt; E_4 &lt; E_5. \\\\\n\\end{aligned}\n\\] Now we will run a new race with the champions of each group and by symmetry, we can assume \\(A_1 &lt; B_1 &lt; C_1 &lt; D_1 &lt; E_1.\\) And now, for each horse we find whether or not he could be in the 3 fastest. For instance, the horse \\(D_1\\) is slower that \\(A_1, B_1, C_1\\), so he cannot be in the three fastest. Likewise, the horse \\(B_3\\) is slower that \\(A_1, B_1, B_2\\), so he cannot be in the three fastest. However, the horse \\(B_2\\) is only slower that \\(A_1, B_1\\), so he is a possible candidate. By doing this for each horse, we find that the possible candidates are \\(A_1, A_2, A_3, B_1, B_2, C_1.\\)\n\\[\n\\begin{aligned}\n& A_1 &lt; A_2 &lt; A_3 &lt; \\cancel{A_4} &lt; \\cancel{A_5} \\\\\n& B_1 &lt; B_2 &lt; \\cancel{B_3} &lt; \\cancel{B_4} &lt; \\cancel{B_5} \\\\\n& C_1 &lt; \\cancel{C_2} &lt; \\cancel{C_3} &lt; \\cancel{C_4} &lt; \\cancel{C_5} \\\\\n& \\cancel{D_1} &lt; \\cancel{D_2} &lt; \\cancel{D_3} &lt; \\cancel{D_4} &lt; \\cancel{D_5} \\\\\n& \\cancel{E_1} &lt; \\cancel{E_2} &lt; \\cancel{E_3} &lt; \\cancel{E_4} &lt; \\cancel{E_5}. \\\\\n\\end{aligned}\n\\] Now, we only have six possible candidates but we already know that \\(A_1\\) is the fastest. So we only need to race \\(A_2, A_3, B_1, B_2, C_1\\) and take the two fastest ones.\nAccordingly, the minimum number of races to identify the three fastest horses is \\(\\boxed{5+ 1 + 1  = 7.}\\)"
  },
  {
    "objectID": "interview_questions/brainteasers/one_bullet_more_prisoners.html",
    "href": "interview_questions/brainteasers/one_bullet_more_prisoners.html",
    "title": "Avoiding prisoners escape",
    "section": "",
    "text": "Let‚Äôs suppose that we are guarding a prison with 100 prisoners each with a probability p_i to try escaping (everyone knows every probability). Assuming that we only have 1 bullet, what is our strategy to be sure that no prisoner will try to escape ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nEach prisoner would rather live than try to escape if he surely dies trying. Thus, the strategy uses recursion that the previous inmate will not try escaping to prove that the next one will not try either.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nLet‚Äôs order our prisoners by their probability of trying to escape \\(p_1 &lt; p_2 &lt;...&lt;p_n.\\) This optimal strategy consists in saying I will kill the inmate with the lowest probability among those who try to escape. Therefore, the prisoner 1 will not try because he knows that he has the lowest probability and if he tries then he will die. Then, the prisoner 2 knows that the first one will not try and so he knows that if he tries, we will be the one with the lowest probability. This reasoning works for every prisoner, so no one will try to escape.\nNB: This also works if we take the highest.\n\n\n\n\n\n\n\n\n\nTipüö® Generalisation\n\n\n\n\n\nThe strategy showed before only works if we can order the probabilities strictly. Indeed, if two inmates have the same probability then the guard will not know which one to shoot since he has only one bullet. Therefore, if they try, they do not die surely (if 2 people have the same probability then there is a chance of 1/2 to survive). Accordingly, the guard will need more bullets. In fact, if there is a group with 2 people with the same probability and another with 3 people with the same probability, he will need 3 bullets to be sure that no one tries to escape. Therefore, if we suppose that there are N prisoners then we have, \\(\\boxed{n_{bullets} = \\text{max}_{1\\le i \\le n} \\; Card(\\{j \\in \\lbrack\\!\\lbrack 1,N \\rbrack\\!\\rbrack| \\; p_j = p_i\\}).}\\)"
  },
  {
    "objectID": "interview_questions/brainteasers/clock_angle.html",
    "href": "interview_questions/brainteasers/clock_angle.html",
    "title": "Determining the angle at 3:15",
    "section": "",
    "text": "Let‚Äôs suppose that a clock shows 3:15, what is the angle between the minute hand and the hour hand ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nBetween 3:00 and 3:15, the hour hand had traveled a bit but how far did it go ?\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nAfter 15 minutes, the minutes hand had made a quarter of a turn so the angle with the x:00 axis is 90¬∞.\nThe hour hand made an angle of 90¬∞ at 3:00. One hour after, at 4:00, it should be at \\(\\frac {4}{12}*360 = 120¬∞.\\) So, in one hour, this hand at turned by 30¬∞ (which means \\(\\frac{30}{4} = 7.5¬∞\\) each quarter hour).\nThus, at 3:15, the angle between the two hands is 7.5¬∞.\n\n\n\n\n\n\n\n\n\n\nTipüö® Generalisation\n\n\n\n\n\nThis generalisation is more like a follow-up question where we have to compute the exact time after 3:00 when the two hands overlap.\nTo compute this, we need the angular speed of each hands: * For the minute one, it takes 60 minutes to do one turn (360¬∞) so we have \\(v_{min} = \\frac{360}{60} = 6 ¬∞/min.\\) * For the hour one, it takes 12 hours to do one turn so we have \\(v_{hour} = \\frac{360}{12*60} = 0.5 ¬∞/min.\\)\nAt 3:00, the initial angle of the minutes hand is 0¬∞ and the initial angle of the hours hand is 90¬∞. Thus we are trying to solve the equation \\(0 + 6*t = 90 + 0.5*t.\\) We find \\(\\boxed{t=\\frac{180}{11} = 16.37 \\;min = 16 \\; min \\; 22 \\; s}\\)"
  },
  {
    "objectID": "interview_questions/brainteasers/fallen_eggs.html",
    "href": "interview_questions/brainteasers/fallen_eggs.html",
    "title": "Fallen eggs",
    "section": "",
    "text": "We have a building with 100 floors and 2 eggs. What is the optimal strategy in order to find the floor where the eggs break by minimizing the worst case scenario ?\n\n\n\n\n\n\nTipüí° Hint (1)\n\n\n\n\n\nIf we try the floor n for the first drop and it breaks then the worst case scenario for the second is to try every floor from 1 to n-1, so the total number of drops would be n.\n\n\n\n\n\n\n\n\n\nTipüí° Hint (2)\n\n\n\n\n\nIf we try the floor n for the first drop and it does not break and then we try the floor 2n and it breaks then the worst case scenario for the second egg is to try every floor from n+1 to 2n-1, so the total number of drops would be n+1. So we need a strategy where for each successful drop of the first egg, we reduce by one unit the worst-case scenario for the second one.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nNaively, if we try a drop at the floor 50 (100/2) and it breaks then in the worst-case scenario we have to try all floors from 1 to 49 so we would need 49 drops for the second egg (in that case, the floor where the egg starts to break is either 49 or 50). So the worst-case scenario would be \\(WC_{\\text{half}} = 1 + 49 = 50 \\; \\text{drops}.\\)\nThe idea is that if the egg breaks at 50 then we don‚Äôt have enough information, thus let‚Äôs try the floor 10 and add 10 each time. If the egg breaks at 50 (5 drops of the first egg to get there), then in the worst-case scenario we have to try all floors from 41 to 49 so we would need 9 additional drops. Accordingly, \\(WC_{\\text{constant}} = 5 + 9 = 14 &lt; WC_{\\text{half}}.\\) We already have a better strategy than the first one. However, if instead of breaking at 50, the first egg breaks at 90, we would still need to test 9 values in the worst-case scenario (81, ‚Ä¶, 89). So the total number of drops will raise to 18. Therefore, we need a strategy where every successful drop of the first egg, leeds to a smaller uncertainty of the second egg by one unit.\nThis optimal strategy would be that at the first drop we try the floor \\(n\\). If it does not succeed then in the worst scenario, we would add n-1 drops (1,2, ‚Ä¶, n-1) so the total amount would be n.¬†If the first drop is a success then we try the floor \\(n + (n-1) = 2n-1\\). If this one does not succeed then in the worst scenario, we would add n-2 drops (n+1, ‚Ä¶, 2n-2) so the total will remain n.¬†Accordingly, we need to find n such that \\(n + (n-1) + (n-2) + ... + 1\\ge100\\) (the sum needs to end at 1 because let‚Äôs say we are at 97 and we try 99 and it fails we don‚Äôt know if it breaks at 98 or 99). The condition is the same as \\(n(n+1)\\ge200.\\) By testing, a few values we find \\(\\boxed{n_{\\text{optimal}} = 14.}\\)\nTherefore, we are trying the floors 14, 27, 39, 50, 60, 69, 77, 84, 90, 95, 99 and the number of total drops in the worst-case scenario is always 14."
  },
  {
    "objectID": "interview_questions/brainteasers/cube_explosion.html",
    "href": "interview_questions/brainteasers/cube_explosion.html",
    "title": "Cube explosion",
    "section": "",
    "text": "Let‚Äôs suppose that we paint a cube on all of its faces. Then we decompose this cube into 27 small cubes. How many small cubes has two faces painted ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nFor every possible number of painted faces, try to count the number of small cubes with that number of painted faces.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nOne small cube cannot have more that 3 faces painted so we will count how many small cube have 0, 1, 2 and 3 painted faces.\n\n\n\n\n\n\n\n\nNumber of painted faces\nNumber of cubes\nExplanation\n\n\n\n\n0\n1\nCenter of the original cube\n\n\n1\n6\nCenter of each face of the original cube\n\n\n3\n8\nAll the vertices of the original cube\n\n\n2\n12\nOn the edge of every face but not on the vertices of the cube"
  },
  {
    "objectID": "interview_questions/brainteasers/poisened_wine.html",
    "href": "interview_questions/brainteasers/poisened_wine.html",
    "title": "Poisened Wine",
    "section": "",
    "text": "Let‚Äôs suppose that we have 1000 bottle of wine but one is poisened. Knowing that the poison takes 24h to be effective and that we need to know which bottle is poisoned in 24 hours, what is the minimum number of mice to find the poisened bottle ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nOne mouse can drink from multiple wines (make a mix).\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nEach mouse can either drink from a specific bottle of wine or not, thus, there are 2 outcomes. If there are \\(n\\) mice, then the total number of outcome covered is \\(2^n\\). Since, we want the minimum number of mice, we have \\(2^{n-1}&lt;1000\\le 2^n\\), thus, \\(\\boxed{n=\\lfloor \\frac{ln(1000)}{ln(2)} \\rfloor} + 1 = 10.\\)"
  },
  {
    "objectID": "interview_questions/brainteasers/groups_equal_heads.html",
    "href": "interview_questions/brainteasers/groups_equal_heads.html",
    "title": "Creating 2 groups with equal heads",
    "section": "",
    "text": "Imagine that we have 100 coins and among them there are 20 heads. Create two groups of coins with the same number of heads.\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nWhat can we do with those coins ? We can only regroup them and flip them.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nMake a group with 20 coins (k Heads unknown), therefore on the remaining 80 there are 20-k Heads. Now just flip each coin of the first group. Now, both groups have exactly the same number of coins. We can prove this result more generally in the next section.\n\n\n\n\n\n\n\n\n\nTipüö® Generalisation\n\n\n\n\n\nLet \\(N\\) be the total number of coins and \\(n\\) the number of heads. We will make a group with \\(m\\) coins and try to find the value of m.\n\n\n\nGroup 1\nGroup 2\n\n\n\n\nNumber coins: m\nN - m\n\n\nNumber heads: k\nn - k\n\n\nNumber tails: m-k\nN-m-n+k\n\n\n\nIf we flip the first group\n\n\n\nGroup 1\nGroup 2\n\n\n\n\nNumber coins: m\nN - m\n\n\nNumber heads: m-k\nn - k\n\n\nNumber tails: k\nN-m-n+k\n\n\n\nWe want \\(m - k = n-k\\) thus \\(\\boxed{m=n.}\\)\nIf we flip the second group\n\n\n\nGroup 1\nGroup 2\n\n\n\n\nNumber coins: m\nN - m\n\n\nNumber heads: k\nN-m-n+k\n\n\nNumber tails: m-k\nn-k\n\n\n\nWe want \\(k=N-m-n+k\\) thus \\(\\boxed{m=N-n.}\\)\nFinally, we find the same solution, we just always have to flip the small group (it is logical since if we flip the big group we would have more heads than 20)"
  },
  {
    "objectID": "interview_questions/brainteasers/average_speed.html",
    "href": "interview_questions/brainteasers/average_speed.html",
    "title": "Average Speed of a train travel",
    "section": "",
    "text": "A train travels at 60 mph on the trip from A to B and 40 mph on the trip from B to A. What is the average speed ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nThis should be pretty straightforward when you introduce the good notations. I can only tell that the average speed is not the average of both speeds (the first trip is faster and will contribute less to the total time).\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nLet \\(v_1 = 60 \\; mph\\) and \\(v_2 = 40 \\; mph\\). Moreover, we introduce the distance \\(d\\) between the points A et B.\nThen, the average speed follows \\(\\bar{v} = \\frac{d+d}{t_1 + t_2}\\) where \\(t_1 = \\frac{d}{v_1}\\) and \\(t_2 = \\frac{d}{v_2}\\). Thus we have \\(\\boxed{\\bar{v}=\\frac{2}{1/v_1 +1/v_2}.}\\) We find \\(\\bar{v}= 48 \\; mph\\)\n\n\n\n\n\n\n\n\n\nTipüö® Average speed paradox\n\n\n\n\n\nLet‚Äôs assume that a runner does a lap at a speed v. At what speed does he have to run on the second lap to have an average speed of 2v ?\nThe answers lays in the fact that we want \\(\\bar{v}=2*v_1\\). Accordingly, the formula seen before leads to \\(2v_1 = \\frac{2}{1/v_1 +1/v_2}\\), the only solution would be that \\(\\boxed{v_2 \\rightarrow + \\infty.}\\)"
  },
  {
    "objectID": "interview_questions/brainteasers/wind_effect.html",
    "href": "interview_questions/brainteasers/wind_effect.html",
    "title": "Wind effect on a plane",
    "section": "",
    "text": "One plane does a round trip from A to B in a straight line. Compare the time of the round trip if there is no wind and if there is a constant wind.\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nYou can either use intuition about the effect of the wind during the trip A-B and during the trip B-A or you can use basic physics by introducing the speed of the plane and the speed of the wind.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nLet‚Äôs assume a constant wind in the direction A towards B.\nFor the intuition part, the wind will make the plane go faster on the trip A-B but slower on the trip B-A. Thus, the trip A-B will take less time than the trip B-A and the advantage of being in the same direction as the wind will weight less than the disadvantage of facing the wind. Therefore, the round trip will take more time if there is wind.\nMathematically, let \\(s\\) be the speed of the plane without wind, \\(w\\) be the speed of the wind and \\(d\\) the distance AB. Since time is additive, if no wind we have \\(t_{\\text{no wind}}=t_{AB} + t_{BA} = \\frac{d}{s} + \\frac{d}{s} = \\frac{2d}{s}.\\) Now, in there is wind in the direction A to B, then the speed on the trip A-B will be \\(s+w\\) and the speed on the trip B-A will be \\(s-w\\). Thus, we have \\(t_{\\text{wind}}=t_{AB} + t_{BA} = \\frac{d}{s+w} + \\frac{d}{s-w} = \\frac{2ds}{s^2-w^2} = \\frac{2d}{s-w^2/s}.\\) Since \\(w^2/s&gt;0\\), we have \\(\\boxed{t_{\\text{wind}} &gt; t_{\\text{no wind}}.}\\)"
  },
  {
    "objectID": "interview_questions/brainteasers/invisible_hats.html",
    "href": "interview_questions/brainteasers/invisible_hats.html",
    "title": "Prisoners random hat",
    "section": "",
    "text": "We have 100 prisoners facing a wall forming a line each wearing a hat either blue or red. The prisoners have to call the color of their hat knowing that they can see those in front of them but not theirs and they can hear the calls of everyone. If a inmate calls the wrong color then he dies. What is the best strategy to save as many prisoners as possible ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nYou cannot be sure that everyone is safe.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nThe best strategy is the following:\n\nThe first one counts the number of red hats in front of him. If this number is even, he calls red. If not, he calls blue. Assuming purely randomness, the probability that this inmate dies is 1/2.\nThe second one knows if the number of red hats (including himself) is even or odd. Then, we counts the number of red hats in front of him. If the parity is the same, he has a blue hat. Otherwise, he has a red hat. This inmate will surely live.\nThe third one will be exactly has the second one. Indeed, based on the call of the second one (if second calls red then one red hat less), he will know the parity of the number of red hats (including himself), he just need to count the ones in front of him to live.\n\nFinally, this strategy surely saves 99 prisoners and lets the final with a probability of 1/2 to live."
  },
  {
    "objectID": "interview_questions/brainteasers/circular_track_ratio.html",
    "href": "interview_questions/brainteasers/circular_track_ratio.html",
    "title": "Computing ratio speed on a circular track",
    "section": "",
    "text": "Assume that two runners are on a circular track. If they run in opposite direction, they meet in 10 minutes. If they run in the same direction, they meet in 60 minutes. What is the ratio of their speed ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nSince you know the times, computing the speed should be easy if you know the distance in each case.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nLet‚Äôs denote by \\(v_1\\) the speed of the fastest and \\(v_2\\) the speed of the other runner. Also, let \\(t_1= 10 \\; \\text{minutes}\\), \\(t_2= 60 \\; \\text{minutes}\\) and \\(d\\) the distance of the track.\n\nIf they run in opposite direction, then when they meet, the distance remaining for one runner is exactly the distance ran by the other. Thus, \\(v_1*t_1 + v_2*t_1 = d\\).\nIf they run in the same direction, then when they meet, the fastest one will have made one more lap that the other. Thus \\(v_1*t_2 = d +  v_2*t_2 .\\)\n\nTherefore, we have \\[\\begin{cases}\n(v_1 + v_2) t_1= d\\\\\n(v_1 - v_2) t_2= d\n\\end{cases}.\\]\nWe then get \\(v_1(t_2-t_1)=v_2(t_1+t_2)\\), accordingly, \\(\\boxed{\\frac{v_1}{v_2}=\\frac{t_1+t_2}{t_2-t_1}=\\frac{7}{5}.}\\)"
  },
  {
    "objectID": "interview_questions/brainteasers/cross_bridge.html",
    "href": "interview_questions/brainteasers/cross_bridge.html",
    "title": "Crossing a bridge in minimum time",
    "section": "",
    "text": "Assume we are during the night and four people need to cross a bridge allowing at most two people to cross at the same time and there is only one flashlight. Knowing that there is one person crossing in 1 minute, one person in 2 minutes, one person in 5 minutes and one person in 10 minutes. What is your strategy so that everyone crosses the bridge in a minimum of time ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nThe fastest need to cross together and the slowest need to cross together.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\n\n1 and 2 cross the bridge (+2 min)\n1 returns (+1 min)\n5 and 10 cross the bridge (+10 min)\n2 returns (+2 min)\n1 and 2 cross the bridge (+2 min)\n\nTotal amount of time 17 minutes."
  },
  {
    "objectID": "interview_questions/brainteasers/squares_grid.html",
    "href": "interview_questions/brainteasers/squares_grid.html",
    "title": "Counting squares in a grid",
    "section": "",
    "text": "Assume we have a \\(n\\times n\\) grid, how many squares are there ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nSeparate all the squares by their size.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\n\n\n\n\n\n\n\n\nSize\nNumber\nExplanation\n\n\n\n\n\\(n\\times n\\)\n1\nThe all grid\n\n\n\\(n-1\\times n-1\\)\n4\nLeaving one row and one column 2*2 possibilites\n\n\n\\(n-2\\times n-2\\)\n9\nLeaving two rows and two columns 3*3 possibilities\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\n\\(1\\times1\\)\n\\(n^2\\)\nAll little squares\n\n\n\nFinally, \\(N = \\sum_{k=1}^n k^2 = \\frac{N(N+1)(2N+1)}{6}\\)"
  },
  {
    "objectID": "interview_questions/brainteasers/wine_water.html",
    "href": "interview_questions/brainteasers/wine_water.html",
    "title": "Wine in water or water in wine ?",
    "section": "",
    "text": "We have two jars with the same capacity. We take a small volume from the water and pour it into the wine. Then, we take the same volume from the jar with the wine and pour it back into the one with the water. Is there more wine in the water or more water in the wine ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nYour chemistry class might save you.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nThe intuition is that if there was more wine then the concentration of the wine would be higher in the small volume so it would be more wine in the water. Since the two jars have the same capacity, the answer is none.\nLet‚Äôs prove that mathematically. We will denote by \\(E\\) the volume of the water (Eau in French) and by \\(V\\) the volume of the wine (Vin in French).\n\nFirst, we do nothing and we compute the proportion of wine in both jars: \\(p_{E_V} = \\frac{0}{E}=0\\), and \\(p_{V_V} = \\frac{V}{V}= 1.\\)\nWe take a volume \\(v\\) from the water and pour it into the wine: \\(p_{E_V} = \\frac{0}{E-v}=0\\), and \\(p_{V_V} = \\frac{V}{V+v}.\\)\nWe take the same volume \\(v\\) from the jar with the wine and pour it back into the water: \\(p_{E_V} = \\frac{\\frac{V}{V+v}*v}{E}=\\frac{Vv}{E(V+v)}\\), and \\(p_{V_V} = \\frac{V}{V+v}.\\)\n\nFinally we compute the proportion of the water in the wine knowing that the sum of both proportions is equal to one: \\(p^*_{E_V} = \\frac{Vv}{E(V+v)}\\) and \\(p^*_{V_E} = 1 - \\frac{V}{V+v} = \\frac{v}{V+v}\\). Therefore \\(\\boxed{\\frac{p^*_{E_V}}{p^*_{V_E}}=\\frac{V}{E}.}\\)\nThe ratio between the proportion of wine in the water by the proportion of water in the wine is equal to the ratio of the capacity of the jar of wine by the capacity of the jar of water."
  },
  {
    "objectID": "interview_questions/brainteasers/furtive_spy.html",
    "href": "interview_questions/brainteasers/furtive_spy.html",
    "title": "Catching a furtive spy",
    "section": "",
    "text": "Assume a 1D-axis and a spy that is currently at A&gt;0, and each period of time, he moves by an amount B&gt;0, where A and B are unknown. What is your strategy to be sure to capture the spy ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nMake sure that, over time, you systematically try every possible starting position and every possible step size ‚Äî so that whatever the spy‚Äôs (A,B) are, your strategy will eventually match them.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nWe will use a mapping \\(\\mathbb{N} \\rightarrow \\mathbb{N} *\\mathbb{N}\\). More precisely, by induction, we prove that \\(\\forall n \\in \\mathbb{N}, \\exists! \\;(p,q)\\in  \\mathbb{N} *\\mathbb{N}, n=2^p(2q+1).\\) Therefore, for each time step \\(n\\), we compute the corresponding \\(p\\) and \\(q\\) and we position ourselves at \\(\\text{Position} = p + n*q\\).\nFor \\(p=A\\) and \\(q=B\\), we have \\(n_0 = 2^A(2B+1)\\) and at that time, our position is \\(\\text{Position} = p + n_0*q = A + n_0*B\\) which is exactly the position of the spy.\n\n\n\nWhat happens if we don‚Äôt assume anymore that the coefficients are positive ?"
  },
  {
    "objectID": "interview_questions/brainteasers/polyglot.html",
    "href": "interview_questions/brainteasers/polyglot.html",
    "title": "Polyglots in society",
    "section": "",
    "text": "There are 70 people in a city. If we take any pair of people (X,Y), there is at least one language spoken by X and not spoken by Y and at least one language spoken by Y and not spoken by X. What is the minimum number of languages spoken in this town ?\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nHow many languages speak the person with most languages and how many languages speak the person with least languages ?\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nThe condition about the pair (X,Y) indicates that the subsets of languages spoken by each person are not comparable for the inclusion. Indeed, every person has to speak the same number of languages (If there is one person with one language more, we can find one speaking all the same except for one and the condition is not fulfilled anymore).\nNow, if there are \\(n\\) languages spoken and each person speaks \\(k\\) languages, then the number of different subsets that we can make is \\(\\binom{n}{k}\\). In order to maximize this number when \\(n\\) is fixed, we can use the Pascal‚Äôs triangle and prove that the maximum is for \\(k = \\lfloor n/2 \\rfloor\\). Accordingly we search for $ $\nThus, the minimum number of languages is 8 and each person speaks 4 languages."
  },
  {
    "objectID": "interview_questions/brainteasers/unique_lighter_coin.html",
    "href": "interview_questions/brainteasers/unique_lighter_coin.html",
    "title": "Finding a lighter coin with minimum weightings",
    "section": "",
    "text": "Let‚Äôs suppose that we have 100 coins but one is lighter that the others. Find the minimum number of weightings to identify this fake coin.\n\n\n\n\n\n\nTipüí° Hint\n\n\n\n\n\nTry to think about how many outcomes can one weighting differentiate.\n\n\n\n\n\n\n\n\n\nTipüí° Solution\n\n\n\n\n\nEach weighing can lead to three different outcomes:\n\nThe left part is heavier\nThe left part is lighter\nThe left part and the right part have same weight\n\nNow we can find the strategy:\n\nFirst weighting : 33 vs 33 (34 left)\nSecond weighting:\n\nIf one of the groups was lighter: 11 vs 11 (11 left)\nIf same weight: 11 vs 11 (12 left)\n\nThird weighting:\n\nIf the second case led to same weight : 4 vs 4 (4 left)\nIf not: 4 vs 4 (3 left)\n\nFourth weighting:\n\nIf the second case led to same weight: 1 vs 1 (1 left) ‚úÖ\nIf not : 1 vs 1 (2 left)\n\nFifth weighting:\n\nIf the second case led to different weights: ‚úÖ\nIf not : 1 vs 1 (0 left) ‚úÖ\n\n\nSo the minimum number of weighting to be sure to identify the fake coin in n = 5.\n\n\n\n\n\n\n\n\n\nTipüö® Generalisation\n\n\n\n\n\nWe can try to generalise this strategy. Let‚Äôs assume that there are \\(N\\) coins with one fake. Then since each weighting leads to \\(3\\) different outcomes, we can identify the fake coins with \\(n\\) weightings if \\(3^n&gt;N\\). We want the minimum number of weightings to be sure to identify the coin, thus \\[3^{n-1}&lt;N \\le 3^n.\\] Accordingly, we have \\[n = \\lfloor \\frac {ln(N)}{ln(3)} \\rfloor + 1 .\\] With \\(N=100\\), we find indeed \\(n=5\\)."
  }
]